---
title: "Develop screening model based on FAISS outputs"
author: "O'Hara"
format: 
  html:
    code-fold: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: source
---

This script takes the .csv files output by `1_faiss_criteria_query.qmd` and insights from `2_faiss_examine_results.qmd` to develop and train a screening model for the overall citation set.

* For each phrase category (remote sensing, societal benefit, valuation methodology) identify the phrase with the greatest similarity (lowest score) and keep only that.
* Examine how well remaining phrases can predict inclusion vs exclusion on the SBR
    * Try various models: logistic regression, random forest, maybe neural networks
    * Model selection using cross validation in `tidymodels` package
    * Examine success metrics e.g., AUC to identify potential thresholds for exclusion

```{r}
library(tidyverse)
library(ggfortify)   ### for PCA plots
library(here)
library(tidymodels)
library(corrplot)

```

## Load query results

```{r}
faiss_query_fs <- list.files(here('3_sentence_transformer_similarity_ranking', 
                                  'faiss_out'), pattern = 'faiss_min', 
                                  full.names = TRUE)

faiss_q_df <- lapply(faiss_query_fs, FUN = function(f) {
  ## f <- faiss_query_fs[1]
  q <- basename(f) %>% str_remove_all('faiss_min_|.csv')
  df <- read_csv(f, show_col_types = FALSE) %>%
    mutate(query = q) %>%
    select(dist, query, citation)
}) %>%
  bind_rows() %>%
  mutate(criteria = str_extract(query, '^[a-z]'),
         query = str_remove(query, '[a-z]_'))
```


## Load references from Societal Benefits Repository

We can compare the screened results from the SBR to the distance values here, perhaps via PCA, clustering, logistic regression...

Note: `_data/societal_benefits/sbr_screened_results_240429.csv` is the citation screening results; `_output/societal_benefits/fulltext_screened.csv` is the full text screening results (does not include those excluded in the citation screening).

```{r}
cit_scr_df <- read_csv(here('_data/societal_benefits/sbr_screened_results_240429.csv')) %>%
  mutate(title = str_to_title(title))

fulltext_df <- read_csv(here('_output/societal_benefits/fulltext_screened.csv')) %>%
  ### skip author, match by title only?
  select(title, screening_decision, reason_for_exclusion, notes = `Quick notes`) %>%
  mutate(title = str_to_title(title))

screened_df <- cit_scr_df %>%
  full_join(fulltext_df) %>%
  mutate(decision = ifelse(is.na(screening_decision), screening_status, tolower(screening_decision))) %>%
  mutate(decision = str_replace(decision, 'cluded', 'clude'))


rescale <- function(x) {
  1 - (x - min(x)) / (max(x) - min(x))
}

sbr_vs_faiss <- screened_df %>%
  select(author, title, decision, tags, key) %>%
  left_join(faiss_q_df, by = c('key' = 'citation')) %>%
  ### find the lowest distance among queries in the category
  # group_by(author, title, criteria) %>%
  # filter(dist == min(dist)) %>%
  ### convert distance to relevance: low distance = high relevance
  group_by(query) %>%
  mutate(dist_norm = rescale(dist)) %>%
  ungroup() 

sbr_dist_mean <- sbr_vs_faiss %>%
  group_by(author, title, decision, tags, key, criteria) %>%
  summarize(dist = mean(dist_norm)) %>%
  ungroup()

sbr_score <- sbr_dist_mean %>%
  group_by(author, title, decision, tags, key) %>%
  summarize(score = prod(dist)^(1/3)) %>%
  ungroup() %>%
  mutate(decision = factor(decision))
  

```

## Does this super simple model work?


```{r}
score_mdl <- glm(decision ~ score, data = sbr_score, family = 'binomial')

score_pred <- sbr_score %>%
  mutate(pred = predict(score_mdl, sbr_score, type = 'response'))

