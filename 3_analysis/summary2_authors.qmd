---
title: "Network plot of authorship"
author: "O'Hara"
format: 
  html:
    code-fold: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: source
---

```{r setup}
library(tidyverse)
library(here)
library(synthesisr)
library(igraph)
# library(ggnet2)

library(GGally)
library(network)
library(sna)
library(ggrepel)
library(cowplot)

library(jsonlite) ### for CrossRef API
```

# Summary

Read in the includes data, including full author lists, and create a network plot of authorship.  This script follows tips from:

> Ognyanova, K. (2024) Network visualization with R. Retrieved from www.kateto.net/network-visualization.



# Methods

## Read and clean author fields for all "includes"

Keep only title and author fields.  The `key` field is not complete for early fulltext screening, but title should be unique.  Author format will be last name, first initial except where first initial is not unique (e.g., Rita and Roland Roberts), in which case first and middle initials will be used.

```{r}
clean_text <- function(t) {
  t %>%
    str_replace_all('\\\\~n', 'ñ') %>%   ### replace "\~n" with ñ
    str_replace_all("\\\\'a", 'á') %>%   ### replace "\'a" with ñ
    str_replace_all("‐", "-") %>%        ### replace hyphen with dash
    str_remove('\\\\relax') %>%          ### remove "\relax" from some author names
    str_remove_all('\\{|\\}') %>%        ### remove curly braces
    str_remove_all('\\\\') %>%            ### remove backslashes
    str_squish()
}

make_short <- function(t) {
  clean_text(t) %>% tolower() %>% str_sub(1, 50)
}

refs_raw <- read_refs(here('_data/screened_fulltext/convei_includes.bib')) %>%
  mutate(key = str_remove_all(key, '\\\\'))

ref_key_lookup <- read_csv(here('_data/1c_refs_clean/ref_key_lookup.csv')) %>%
  select(title, key2 = key) %>%
  mutate(title_short = make_short(title)) %>%
  mutate(title_short = str_replace(title_short, 'el nino', 'el niño')) %>%
  select(-title)


refs_clean <- refs_raw %>%
  mutate(title_short = make_short(title)) %>%
  inner_join(ref_key_lookup, by = 'title_short') %>%
  select(title, author, key = key2) %>%
  mutate(author = str_split(author, ' and ')) %>% 
  unnest(author) %>%
  ### establish first author status
  group_by(title, key) %>%
  mutate(lead_author = author == first(author)) %>%
  ungroup() %>%
  ### clean title and author names
  mutate(title_clean = clean_text(title)) %>%
  mutate(author = clean_text(author)) %>%
  ### separate name into last, first format
  separate(author, into = c('last', 'first'), sep = ',', remove = FALSE) %>%
  rename(author_full = author) %>%
  mutate(last = ifelse(tolower(last) == 'mccarl', 'McCarl', last)) %>%
  mutate(first = str_squish(first) %>% str_to_title()) %>%
  ### fix first names to include middle init where available, for consistency
  mutate(first = case_when(last == 'Bernknopf' ~ 'Richard L',
                           last == 'Bouma' ~ 'Jetske A',
                           last == 'Dekker' ~ 'Arnold G',
                           last == 'Kuik' ~ 'Onno J',
                           last == 'Macauley' ~ 'Molly K',
                           last == 'Brookshire' ~ 'David S',
                           last == 'Podestá' ~ 'Guillermo P',
                           last == 'Raunikar' ~ 'R P',
                           last == 'Richardson' ~ 'Leslie A',
                           last == 'Seelan' ~ 'SK',
                           last == 'Solow' ~ 'Andrew R',
                           last == 'Weiher' ~ 'Rodney F',
                           last == 'Wilson' & first == 'J.' ~ 'James W',
                           last == 'Koontz' & first == 'Steve' ~ 'Stephen R',
                           last == 'Mishra' & first == 'Shruti' ~ 'Shruti K',
                           last == 'McCarl' & first == 'Bruce' ~ 'Bruce A',
                           last == "O'Brien" & first == 'James' ~ 'James J',
                           last == 'Miller' & first == 'Holly' ~ 'Holly M',
                           str_detect(title, 'Sydney 2000') & last == 'Roberts' ~ 'Rita D',
                           TRUE ~ first)) %>%
  mutate(first = str_remove_all(first, '[^A-Z]')) %>%
  mutate(first_letter = str_sub(first, 1, 1)) %>%
  ### if initial of first/middle name is unique, use only first initial
  group_by(last, first_letter) %>%
  mutate(n = n_distinct(first)) %>%
  ungroup() %>%
  mutate(first = ifelse(n == 1, first_letter, first)) %>%
  ### recombine first and last names into author id
  mutate(author = str_c(last, ', ', first)) %>%
  select(title = title_clean, author, author_full, lead_author, key, doi)

### To simplify the plot, omit any papers where no authors have more than X papers,
### i.e., at least one author has multiple papers
refs_multi <- refs_clean %>%
  group_by(author) %>%
  mutate(n_papers = n_distinct(title)) %>%
  group_by(title) %>%
  filter(any(n_papers > 2)) %>%
  ungroup()
  
```

Check journals for ideas for where to submit manuscript?

```{r}
journals <- refs_raw %>%
  select(key, title, journal) %>%
  mutate(journal = str_to_title(journal)) %>%
  group_by(journal) %>%
  summarize(n = n())
```

Get methods to check clusters against paper methods.

```{r}
methods_df <- readxl::read_excel(here('_data/screened_fulltext/ft_consolidated_coding.xlsx')) %>%
  janitor::clean_names() %>%
  filter(key %in% refs_multi$key)
```



## Set up nodes and edges

Nodes are authors; edges are co-authorship relationships.  The `lead` field indicates whether the author is a lead author on at least one publication.

Annoyingly the ID columns are position-dependent not name dependent!

```{r}
nodes <- refs_multi %>%
  group_by(author) %>%
  summarize(lead = any(lead_author),
            n_papers = n()) %>%
  select(author, lead, n_papers) %>%
  mutate(label = ifelse(n_papers > 2, author, NA))

edges <- refs_multi %>%
  left_join(refs_clean, by = 'title') %>%
  ### discard same-author edges and reversed matches (e.g., A -> B and B -> A)
  filter(author.x > author.y) %>%
  select(from = author.x, to = author.y) %>%
  group_by(from, to) %>%
  summarize(weight = n())

```

Set up plot:

* Node size based on number of papers (not number of connections)
* Node color based on lead author status

```{r}
#| eval: false

net <- graph_from_data_frame(d = edges, vertices = nodes, directed = FALSE) %>%
  simplify(remove.multiple = F, remove.loops = T)

### Set up vertex attributes
V(net)$size <- nodes$n_papers * 2
V(net)$color <- ifelse(nodes$lead, 'coral', 'gray80')
V(net)$label <- nodes$label

### set up edge attributes
E(net)$width <- E(net)$weight^2 / 2
# edge_pal <- c('grey95', 'grey90', 'grey85', 'grey80')
# E(net)$color <- edge_pal[E(net)$weight]
E(net)$color <- 'grey80'

plot(net, edge.curved = 0.1,
     vertex.label.family = 'sans', vertex.label.color = 'black', vertex.label.cex = 0.6,
     # vertex.label.dist = 1.5, vertex.label.degree = 0,
     vertex.frame.color = NA,
     layout = layout_nicely)
# legend(x="bottomleft", c("Lead author", "none"), pch=21,
#        col=NA, pt.bg=c('coral', 'gray80'), pt.cex=2, cex=.8, bty="n", ncol=1)

```

## Inspect clusters for preferred methods and societal benefit areas:

* Cluster 1: Bernknopf/Brookshire/Kuwuyama: (various)
    * Bernknopf VOI/Bayesian
    * Brookshire Bayesian
    * Kuwuyama VOI/Bayesian
* Cluster 2: Cooke: (climate, ag)
    * Cooke VOI/Real Options
* Cluster 3: Adams/Weiher/McCarl: (ENSO prediction for agriculture)
    * Adams VOI/Bayesian
    * Weiher Bayesian/VOI
    * McCarl Bayesian/VOI
* Cluster 4:Obersteiner/Bouma/Fritz/Dekker/Kuik: (various sba)
    * Obersteiner VOI/CBA (wildland fires, disasters)
    * Bouma Bayesian/surveys (conservation)
    * Fritz CBA/surveys
    * Dekker Bayesian/surveys (ag, ecosystems)
    * Kuik Bayesian/surveys (ag, ecosystems)
* Cluster 5: Diana: (agriculture, social values)
    * Diana Focus groups/surveys/semi-structured interviews/econometric
* Cluster 6: Gobakken/Naesset: (forest inventory)
    * Gobakken VOI/CBA
    * Naesset VOI/CBA

## Try plotting with `ggnet2`

```{r}
set.seed(999)
edges2 <- refs_multi %>%
  left_join(refs_clean, by = 'title') %>%
  ### discard reversed matches (e.g., A -> B and B -> A)
  filter(author.x >= author.y) %>%
  select(from = author.x, to = author.y) %>%
  group_by(from, to) %>%
  summarize(weight = n(), .groups = 'drop') %>%
  mutate(weight = ifelse(from == to, 0, weight)) %>%
  pivot_wider(names_from = to, values_from = weight, values_fill = 0) %>%
  column_to_rownames('from') %>%
  as.matrix()

net2 <- edges2 %>%
  network(matrix.type = "adjacency",
          names.eval = "weights",
          loops = FALSE, directed = FALSE)

# vertex names
network.vertex.names(net2) <- row.names(edges2)

### set up attributes
net2 %v% 'label' <- nodes$label
net2 %v% 'lead' <- nodes$lead
net2 %v% 'n_papers' <- nodes$n_papers

net_p <- ggnet2(net2, mode = 'kamadakawai',
       color = "lead",
       size  = "n_papers",
       label = "label",
       label.size = 4,
       edge.color = 'grey80') +
  scale_color_manual(values = c('grey80', 'coral')) +
  theme(legend.position = 'none')

net_p
p <- ggdraw() +
  draw_plot(net_p) +
  draw_plot_label(label = LETTERS[1:6],
                  x = c(0.23, 0.70, 0.95, 0.94, 0.45, 0.10), y = c(0.93, 0.97, 0.71, 0.36, 0.15, 0.29),
                  size = 14,
                  color = 'black')
p
```

## identify authors within clusters?

```{r}
x <- edges %>% 
  select(-weight) %>% 
  group_by(from) %>% mutate(min1 = min(to)) %>% 
  group_by(to) %>% mutate(min2 = min(min1)) %>%
  group_by(min1) %>% mutate(min3 = min(min2)) %>%
  group_by(min2) %>% mutate(min4 = min(min3)) %>%
  ungroup()

# x %>% filter(min4 != min3) ### no matches

y <- x %>% select(to, from, node = min3) %>%
  distinct() %>%
  mutate(node = factor(node),
         node_num = as.integer(node)) %>%
  pivot_longer(-node_num, names_to = "type", values_to = "author") %>%
  left_join(refs_multi %>% select(author, n_papers) %>% distinct(), by = "author") %>%
  group_by(node_num) %>%
  mutate(node_author = author[which(n_papers == max(n_papers))[1]]) %>%
  ungroup()

papers_clusters <- refs_multi %>%
  left_join(y, by = c('author' = 'author')) %>%
  select(node_author, title, key, node_num) %>%
  distinct() %>%
  left_join(methods_df %>% select(-title), by = 'key')

methods_by_cluster <- papers_clusters %>% 
  pivot_longer(cols = c(method_1, method_2)) %>%
  select(node_author, key, node_num, value) %>%
  filter(!is.na(value)) %>%
  group_by(node_num) %>%
  mutate(n_papers = n_distinct(key)) %>%
  group_by(node_num, node_author, n_papers, value) %>%
  summarize(n = n(),
            .groups = 'drop') %>%
  mutate(pct = round(n / n_papers * 100))

DT::datatable(methods_by_cluster)

values_by_cluster <- papers_clusters %>% 
  mutate(sba = str_split(societal_benefit_type, ';')) %>%
  unnest(sba) %>%
  select(key, node_num, node_author, sba) %>%
  filter(!is.na(sba)) %>%
  group_by(node_num) %>%
  mutate(n_papers = n_distinct(key)) %>%
  group_by(node_num, node_author, n_papers, sba) %>%
  summarize(n = n(),
            .groups = 'drop') %>%
  mutate(pct = round(n / n_papers * 100))

DT::datatable(values_by_cluster)

sbas_by_cluster <- papers_clusters %>% 
  pivot_longer(cols = contains(c('geoss', 'nasa'))) %>%
  mutate(value = case_when(str_detect(tolower(value), 'fire') ~ 'Wildfire',
                           str_detect(value, '^Eco') ~ 'Ecosystem',
                           TRUE ~ str_remove(value, ' .+'))) %>%
  select(node_author, key, node_num, value) %>%
  distinct() %>%
  filter(!is.na(value)) %>%
  group_by(node_num) %>%
  mutate(n_papers = n_distinct(key)) %>%
  group_by(node_num, node_author, n_papers, value) %>%
  summarize(n = n(),
            .groups = 'drop') %>%
  mutate(pct = round(n / n_papers * 100))

DT::datatable(sbas_by_cluster)
```


## Gather Affiliations

### Use CrossRef API to access author affiliations

```{r}
endpt_stem <- 'https://api.crossref.org/works/%s'

doi_vec <- includes_doi$doi

get_affil_crossref <- function(doi) {
  ### doi <- doi_vec[14]
  x <- tryCatch(fromJSON(sprintf(endpt_stem, doi))$message$author, 
                error = function(e) {return(NA)})
  if (!is.data.frame(x)) {
    return(data.frame(doi = doi, error = 'try error'))
  } else {
    x <- x %>%
      rowwise() %>%
      mutate(affiliation = ifelse(length(affiliation) == 0, NA, affiliation)) %>%
      ungroup() %>%
      unnest(affiliation) %>%
      mutate(doi = doi)
    Sys.sleep(0.5)
    return(x)
  }
}
```

```{r}
key_doi_lookup <- read_csv(here('_data/1c_refs_clean/ref_key_lookup.csv')) %>%
  select(key, doi)
clusters_doi <- papers_clusters %>% 
  inner_join(key_doi_lookup, by = 'key')

affil_cr_f <- here('3_analysis/author_affiliations_crossref.csv')

if(!file.exists(affil_out_f)) {

  affil_df_cr <- purrr::map_df(doi_vec, get_affil_crossref)
  
  write_csv(affil_df_cr, affil_cr_f)
}

affil_df_cr <- read_csv(affil_cr_f)

x <- inner_join(affil_df_cr, clusters_doi, by = 'doi') %>% filter(!is.na(affiliation))
x$title %>% n_distinct()
```

A bust - only five out of 36 papers in the clusters have author affiliation info.

### Inclusion in the Web of Science search

Web of Science results include affiliations!  But at the paper level, not the author level.  Note: the `wos_clean_240126.ris` file is post-de-duplication, which prioritizes databases in this order: SBR, WoS, Scopus.  So, let's go back to the full WoS results, pre-processed prior to de-duplication.  No affiliations in Scopus unless it's in a two-letter column (out of 327 variables)

```{r read in the preprocessed WoS citations}
wos_fs <- list.files(here('_data/1b_refs_preprocessed'), pattern = 'wos_', full.names = TRUE)
wos_all <- parallel::mclapply(wos_fs, read_refs, mc.cores = 1) %>% 
  bind_rows() %>% 
  mutate(src = 'wos')

includes_df <- readxl::read_excel(here('_data/screened_fulltext/ft_consolidated_coding.xlsx'))

all_refs_doi <- read_csv(here('_data/1c_refs_clean/ref_key_lookup.csv')) %>%
  mutate(doi = str_remove(doi, '.+doi.org/|https?://'))

includes_doi <- all_refs_doi %>%
  filter(key %in% includes_df$key)

# table(includes_doi$src)
# scopus societal benefits repo                    wos 
#     20                     73                     77 

clusters_doi <- all_refs_doi %>%
  filter(key %in% papers_clusters$key)
# table(clusters_doi$src)
# scopus societal benefits repo                    wos 
#      7                     25                      4 

wos_clean <- wos_all %>%
  select(id = unique_id, author, affiliations, title, year, doi) %>%
  distinct()

wos_include <- wos_clean %>%
  filter(doi %in% includes_doi$doi)
### 76 of 77 'wos' source (plus however many duped in SBR), matched by doi alone

wos_cluster <- wos_clean %>%
  filter(doi %in% clusters_doi$doi)
```

```


