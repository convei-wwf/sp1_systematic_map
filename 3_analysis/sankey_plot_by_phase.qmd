---
title: "Sankey diagram of includes/excludes by phase"
author: "O'Hara"
format: 
  html:
    code-fold: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: source
---

```{r setup}
library(tidyverse)
library(here)
library(networkD3)

```

# Summary

Load refs at various phases.  Include:

* SBR start
* Training set start
* Classification set start

* Colandr includes
* Colandr excludes
* Colandr not loaded (deprioritized)

* Full text includes
* Full text excludes
* Full text not done

NOTE: some in the early stages were revisited after rejecting in Colandr for "not ESI" when we expanded the scope of ESI, and subsequently added to full text review.  Identify those and switch the Colandr screening status to "include" to resolve the dilemma.

```{r}
### define a function to clean titles of caps, diacritics, etc for easier matching
clean_title <- function(t) {
  tolower(t) %>%
    stringi::stri_trans_general('Latin-ASCII') %>% ### drop diacritics
    str_remove_all('[^a-z0-9 ]+') %>% ### drop punctuation
    str_squish() %>%
    str_sub(1, 60)
}
```

```{r}
ft_fs <- list.files(here('_data/screened_fulltext'), pattern = '_fulltext_', full.names = TRUE) 
ft_df <- ft_fs %>%
  lapply(read_csv) %>%
  setNames(str_remove_all(basename(ft_fs), '._fulltext_|.csv')) %>%
  bind_rows(.id = 'phase') 

ft_sbr <- ft_df %>%
  filter(phase == 'sbr') %>%
  mutate(title2 = clean_title(title))

col_df <- read_csv(here('_data/screened_colandr/colandr_by_phase.csv')) %>%
  mutate(phase = case_when(phase == 'classifier round 1' ~ 'training',
                           phase == 'early' ~ 'training',
                           phase == 'sample 1000' ~ 'training',
                           phase == 'classifier excl sample' ~ phase,
                           str_detect(phase, 'class') ~ 'pred_incl',
                           TRUE ~ phase)) %>%
  mutate(fix = clean_title(title) %in% ft_sbr$title2 & 
           screening_status == 'excluded') %>%
  mutate(screening_status = ifelse(fix, 'included', screening_status)) %>%
  select(-fix)

col_totals_df <- col_df %>%
  group_by(screening_status) %>%
  summarize(n = n(), .groups = 'drop')

col_phase_df <- col_df %>%
  group_by(phase, screening_status) %>%
  summarize(n = n(), .groups = 'drop')


ft_totals_df <- ft_df %>%
  group_by(screening_decision) %>%
  summarize(n = n(), .groups = 'drop')

ft_phase_df <- ft_df %>%
  mutate(phase = case_when(phase == 'classifier_round1' ~ 'training',
                           phase == 'sample1000' ~ 'training',
                           phase == 'classifier excl sample' ~ phase,
                           str_detect(phase, 'class') ~ 'pred_incl',
                           TRUE ~ phase)) %>%
  group_by(phase, screening_decision) %>%
  summarize(n = n(), .groups = 'drop')


pred_round2 <- read_csv(here('_data/classifier_results',
                             'predicted_classifier_round2_set.csv'))
table(pred_round2$classification_prediction)

total <- read_csv(here('_data/1c_refs_clean/ref_key_lookup.csv'))
col_ct <- sum(col_df$n)
ft_ct <- sum(ft_df$n)
```

### Totals for Colandr

* 3813 screened in Colandr
  * 777 included
    * 144 SBR
    * 144 training
    * 489 pred include
    * (13 final check - drop these)
  * 2837 excluded
    * 111 SBR
    * 928 training
    * 1798 pred include
    * (186 final check - drop these)

Totals by phase

* 255 SBR
* 1072 training
* 2287 predicted includes
* 10,206 predicted excludes
  * 200 screened to check
  * 10,006 not screened

### Totals for Full Text

* 170 includes
  * 73 SBR
  * 13 training
  * 84 predicted includes
* 590 excluded
  * 66 SBR
  * 119 training
  * 405 predicted includes


```{r}
links <- tribble(
  ~source,            ~target,            ~value,
  'Soc Benefit Repo (n = 255)',         'Title/abstract includes (n = 760)',      144,
  'Soc Benefit Repo (n = 255)',         'Title/abstract excludes (n = 2,854)',    111,
  'Training set (n = 1,072)',           'Title/abstract includes (n = 760)',      147,
  'Training set (n = 1,072)',           'Title/abstract excludes (n = 2,854)',    930,
  'Predicted includes (n = 2,287)',     'Title/abstract includes (n = 760)',      489,
  'Predicted includes (n = 2,287)',     'Title/abstract excludes (n = 2,854)',   1798,
  'Predicted excludes (n = 10,206)',    'Not screened (n = 10,006)',             9884,
  'Predicted excludes (n = 10,206)',    'Title/abstract exclude check (n = 200)', 500,
  'Title/abstract includes (n = 760)',     'Fulltext includes (n = 170)',         208,
  'Title/abstract includes (n = 760)',     'Fulltext excludes (n = 590)',         649) %>%
  arrange(value) %>%
  mutate(source = fct_inorder(source)) %>%
  group_by(source) %>%
  mutate(n = sum(value)) %>%
  ungroup()
 
# From these flows we need to create a node data frame: it lists every entities involved in the flow
nodes <- data.frame(
  name=c(as.character(links$source), 
  as.character(links$target)) %>% unique()
)
 
# With networkD3, connection must be provided using id, not using real name like in the links dataframe.. So we need to reformat it.
links$IDsource <- match(links$source, nodes$name)-1 
links$IDtarget <- match(links$target, nodes$name)-1
 
# Make the Network
p <- sankeyNetwork(Links = links, Nodes = nodes,
              Source = "IDsource", Target = "IDtarget",
              Value = "value", NodeID = "name", 
              fontSize = 14, fontFamily = 'Arial',
              sinksRight=FALSE)
p

# save the widget
# library(htmlwidgets)
# saveWidget(p, file=paste0( getwd(), "/HtmlWidget/sankeyBasic1.html"))
```

```{r}
URL <- paste0('https://cdn.rawgit.com/christophergandrud/networkD3/',
              'master/JSONdata/energy.json')
energy <- jsonlite::fromJSON(URL)

# Plot
sankeyNetwork(Links = energy$links, Nodes = energy$nodes, Source = 'source',
             Target = 'target', Value = 'value', NodeID = 'name',
             units = 'TWh', fontSize = 12, nodeWidth = 30)

# Colour links
energy$links$energy_type <- sub(' .*', '',
                               energy$nodes[energy$links$source + 1, 'name'])

sankeyNetwork(Links = energy$links, Nodes = energy$nodes, Source = 'source',
             Target = 'target', Value = 'value', NodeID = 'name',
             LinkGroup = 'energy_type', NodeGroup = NULL)

```

