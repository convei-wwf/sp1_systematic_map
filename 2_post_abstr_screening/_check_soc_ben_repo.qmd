---
title: "Societal Benefit Repo screening results"
author: "O'Hara"
format: 
  html:
    code-fold: true
    code-summary: "Show me the code"
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: source
---

```{r setup}
library(tidyverse)
library(tidytext)
library(synthesisr)
library(here)
```

# Summary

The 260 unique(?) documents with abstracts represented in the Societal Benefits repository were screened by title and abstract in Colandr.  The results were exported as a .csv.  This document analyzes/summarizes those results.

# Data

The SBR information was downloaded as a .csv on 4/23/24, and uploaded to Colandr.  The screening criteria outlined in the planning/protocol document were used to determine inclusion/exclusion.  Some documents were tagged with additional information, e.g., "maybe" for some included documents that seemed like they may not actually meet the criteria.

The screening results were downloaded as a .csv on 4/29/24.

# Methods

## Read in the screening results

Also, write out included refs with DOI for import into Zotero.

```{r}
sbr_df_raw <- read_refs(here('_data/refs_ris_out/societal_benefits_240423.ris')) %>%
  select(title, author, abstract, journal, year, doi) %>%
  mutate(title = str_squish(title))

sbr_dupes <- janitor::get_dupes(sbr_df_raw, title) %>%
  group_by(title) %>%
  slice(1) %>%
  ungroup()

sbr_df <- sbr_df_raw %>%
  anti_join(sbr_dupes)

sbr_results_df <- read_csv(here('_data/screened/colandr_results_240429.csv')) %>%
  filter(data_source_name == 'Societal Benefits repo') %>%
  select(contains('citation'), -contains('journal')) %>%
  setNames(str_remove(names(.), 'citation_')) %>%
  mutate(title = str_squish(title)) %>%
  select(-abstract, -authors) %>%
  distinct()

sbr_out_df <- sbr_df %>%
  full_join(sbr_results_df, by = c('title'))

sbr_incl_df <- sbr_out_df %>%
  filter(screening_status == 'included')

write_csv(sbr_incl_df, here('_data/screened/included_sbr_2024-04-29.csv'))
```

## Import full texts into Zotero

Pulling the DOI information from these papers, and importing into Zotero via the "add item(s) by identifier" option, downloads (where possible) the PDFs into a designated subcollection.  Checking the successfully downloaded DOIs against the full list, we can identify those references not found via DOI.

```{r}
zot_check <- read_refs(here('_data/screened/included_sbr_zotero_240429.bib')) %>%
  mutate(title_check = str_remove_all(tolower(title), '[[:punct:]]') %>% str_squish(),
         doi = tolower(doi))

doi_find <- sbr_incl_df %>%
  mutate(doi = str_remove(tolower(doi), '.+doi.org/')) %>%
  mutate(title_check = str_remove_all(tolower(title), '[[:punct:]]') %>% str_squish()) %>%
  filter(!doi %in% zot_check$doi) %>%
  filter(!title_check %in% zot_check$title_check)

pdf_find <- zot_check %>% filter(is.na(file))
```

