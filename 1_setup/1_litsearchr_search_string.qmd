---
title: 'Web of Science prelim analysis'
format: 
  html:
    code-fold: true
editor: visual
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
library(tidyverse)
library(tidytext)
library(bib2df)
library(here)
library(litsearchr) ### remotes::install_github('elizagrames/litsearchr', ref = 'main')
library(igraph)
library(ggraph)
library(ggrepel)

source(here('common_fxns.R'))
```

## Description

This script works with several search sets to help methodically identify search strings for a more inclusive literature database search.

### Web of Science

Data includes bibtex entries for the top most relevant results from a Web of Science search using the following terms within the "topic" (i.e., title, abstract, keywords, keywords-plus):

<center>('satellite' <b>OR</b> 'space-based' <b>OR</b> 'remote observation' <b>OR</b> 'remote sensing' <b>OR</b> 'earth observation') <br><b>AND</b><br> ('decision' <b>OR</b> 'optimization' <b>OR</b> 'risk analysis' <b>OR</b> 'operational context' <b>OR</b> 'management' <b>OR</b> 'policy') <br><b>AND</b><br> ('value\*' <b>OR</b> 'valuation' <b>OR</b> 'benefit\*') <b>AND</b> ('social' OR 'societal' OR 'cultural' OR 'socioeconomic')</center>

A search using these terms on August 10, 2023, generated 1158 results, which were downloaded in bibtex format including the full record and all citations (for the Web of Science), must be cleaned to remove forced line breaks for the `bib2df` package to parse it properly.

## Use `litsearchr` functionality

This section is based heavily on https://www.r-bloggers.com/2023/03/automated-systematic-literature-search-using-r-litsearchr-and-google-scholar-web-scraping/. Code is adapted for bibtex data accessed from Web of Science and the CONVEI Zotero library. Where instruction text is (more or less) verbatim from the blog post, it is indicated by block quotes.

### Identify useful terms from title

Use the Rapid Automatic Keyword Extraction (RAKE) algorithm from `litsearchr::extract_terms`, as well as stop word elimination, to extract useful terms from titles.

Now clean, read in the bibtex files and bind into a data.frame. Those with a prefix 'wosnaive\_' are the first pass with the initial set of search terms into Web of Science.

```{r}
article_df <- load_bibtex(pattern = 'wosnaive_', aspect = 'wide') %>%
  select(category, year, 
         # keywords_plus, web_of_science_categories, research_areas,
         title, abstract, keywords)
```

```{r extract title terms}
stop_vec <- stopwords::stopwords('en')
title_terms <- extract_terms(text = article_df$title,
                             method = 'fakerake', min_freq = 3, min_n = 2,
                             stopwords = stop_vec)

# abstr_terms <- extract_terms(text = article_df$abstract,
#                              method = 'fakerake', min_freq = 3, min_n = 2,
#                              stopwords = stop_vec)

```

### Create Co-Occurrence Network

> We will consider the title and abstract of each article to represent the article's 'content' and we will consider a term to have appeared in the article if it appears in either the title or abstract. Based on this we will create the document-feature matrix, where the 'documents' are our articles (title and abstract) and the 'features' are the search terms. The Co-Occurrence Network is computed using this document-feature matrix.

Uses `litsearchr::create_dfm()` to create a document-feature matrix and `litsearchr::create_network()` to create the co-occurrence network.

```{r create cooccurrence network}
article_docs <- paste(article_df$title, article_df$abstract) 
  ### we will consider title and abstract of each article to represent the article's 'content'

article_dfm <- create_dfm(elements = article_docs, 
                          features = title_terms)

article_coocnet <- create_network(article_dfm, min_studies = 3)

ggraph(article_coocnet, layout = 'stress') +
  coord_fixed() +
  expand_limits(x = c(-3, 3)) +
  geom_edge_link(aes(alpha = weight)) +
  geom_node_point(shape = 'circle filled', fill = 'white') +
  geom_node_text(aes(label = name), hjust = 'outward', check_overlap = TRUE) +
  guides(edge_alpha = 'none') +
  theme_void()
```

### Prune the Network based on node strength

#### Compute node strength

> Node strength in a network is calculated by summing up the weights of all edges connected to the respective node.Thus, node strength investigates how strongly it is directly connected to other nodes in the network.

```{r Prune the Network based on node strength}
article_node_strength <- igraph::strength(article_coocnet)
article_node_rankstrength <- data.frame(term = names(article_node_strength), 
                                        strength = article_node_strength, 
                                        row.names = NULL)
article_node_rankstrength$rank <- rank(article_node_rankstrength$strength, 
                                       ties.method = 'min')
article_node_rankstrength <- article_node_rankstrength[order(article_node_rankstrength$rank),]
article_plot_strength <- ggplot(article_node_rankstrength, 
                                aes(x = rank, y = strength, label = term)) +
  geom_line(lwd = 0.8) +
  geom_point() +
  geom_text_repel(size = 3, hjust = 'right', nudge_y = 3, max.overlaps = 30) +
  theme_bw()

article_plot_strength
```

#### Prune based on chosen criteria

> We want to keep only those nodes that have high strength, but how will we decide how many to prune out? `litsearchr::find_cutoff()` provides us with two ways to decide: cumulative cutoff and change points. The cumulative cutoff method simply retains a certain proportion of the total strength. The change points method uses `changepoint::cpt.mean()` under the hood to calculate optimal cutoff positions where the trend in strength shows sharp changes.
>
> Again, we will use the heuristic when in doubt, pool results together, i.e. we will use the change point nearest the to the cumulative cutoff value we set.

```{r Prune based on chosen criteria}
### Cumulatively - retain a certain proportion (e.g. 80%) of the total strength
### of the network of search terms
article_cutoff_cum <- find_cutoff(article_coocnet, method = 'cumulative', 
                                  percent = 0.8)

### Changepoints - certain points along the ranking of terms where the strength 
### of the next strongest term is much greater than that of the previous one
article_cutoff_change <- find_cutoff(article_coocnet, method = 'changepoint', knot_num = 5)

article_plot_strength +
  geom_hline(yintercept = article_cutoff_cum, 
             color = 'red', lwd = 0.7, linetype = 'longdash', alpha = 0.6) +
  geom_hline(yintercept = article_cutoff_change, 
             color = 'orange', lwd = 0.7, linetype = 'dashed', alpha = 0.6)

article_cutoff_crit <- article_cutoff_change[which.min(abs(article_cutoff_change - article_cutoff_cum))] 
  ### e.g. nearest cutpoint to cumulative criterion (cumulative produces one value, changepoints may be many)

article_maxselected_terms <- litsearchr::get_keywords(litsearchr::reduce_graph(article_coocnet, article_cutoff_crit))

```

Inspect selected terms:

`r article_maxselected_terms`

> Some expression already contain others. For example, 'mdma-assisted psychotherapy' is an instance of '-assisted psychotherapy' which is a very important key term that defines psychotherapies that use pharmacological means or other tools to achieve it's results. This happens for a lot of strings, and generally, we would like to keep only the shortest unique substring

In our case, 'earth observations' and 'earth observation system' are instances of 'earth observation'... similar for 'ecosystem service\[s\| value\]'...

```{r keep shortest unique substrings}
superstring <- rep(FALSE, length(article_maxselected_terms))
for(i in seq_along(article_maxselected_terms)) {
  ### i <- 1
  this_term   <- article_maxselected_terms[i]
  other_terms <- article_maxselected_terms[-i]
  superstring[i] <- any(str_detect(this_term, other_terms))
}
article_selected_terms <- article_maxselected_terms[!superstring]
```

> We will also manually do two other changes: (1) we are not interested in 'systematic reviews' so we will remove it; (2) we will add the terms 'psychotherapy' and 'ptsd' as they are not already present in their simplest form.

For our purposes, let's focus on the things not already in our preliminary search terms. Pull those out, then inspect what's left for relevant terms to include.

```{r id new terms}
esi_terms <- 'satellite|space.based|remote observation|remote sensing|earth observation'
decision_terms <- 'decision|optimization|risk analysis|operational context|management|policy'
val_terms1 <- 'value|valuation|benefit'
val_terms2 <- 'social|societal|cultural|socioeconomic'

all_terms <- paste(esi_terms, decision_terms, val_terms1, val_terms2, sep = '|')

topics_new <- article_selected_terms[!str_detect(article_selected_terms, all_terms)]

topics_new
```

Looking for new key terms in the three Venn diagram areas of: "value", "decision", and "earth science information".

-   ESI: Many terms such as "machine learning," "information system," "spatial resolution" may fit here but are too generic to apply specifically to satellite or remote sensing. Some possibilities to include:
    -   aerial vehicle (and/or unmanned aerial)
        -   let's focus on satellites, not drones yet...
    -   remotely sensed
-   Decision support: no terms here seem to fall into this category; we have excluded our preliminary search terms, which implies that no additional terms relevant to this domain showed up as important in the co-occurrence network.
-   Value/benefit: Many of the terms here seem to refer to some state of the world, e.g., "vegetation cover," "river basin," "mangrove forest," "urban areas," but without specifically noting a value or benefit related to these. A few possiblilites appear, however:
    -   terms relating to quality, service, or health (value, benefit)
        -   ecosytem service
        -   ecosystem health
        -   environmental quality
        -   water quality
    -   terms relating to goals or implied importance (value)
        -   sustainable development goal
        -   protected area
        -   heritage site

All told, these added criteria expand the search results from 1163 to 6419 (on Aug 14 2023).

Additional term ideas based on scanning benchmarks:

-   add "investment" as a decision as well as "cost benefit analysis"
-   explictly include "economic" and "environmental" in value term
-   include "*equit*"

## Final search terms

Here are the "final" search terms, including number of individual hits for the term. Number of *unique* hits is based on subtracting that term (within its Venn bubble) holding all other terms constant and determining the hits that no longer appear (performed on Oct 23, 2023, with 3742 total hits with all terms included).

-   Earth science information (all connected with OR)
    -   "satellite" (+838 hits)
    -   "space-based" (+57 hits)
    -   "remote observation" (+0 hits) - dropped
    -   "remote sensing" (+1050 hits)
    -   "earth observation" (+66 hits)
    -   "remotely sens\*" (+97 hits)
    -   "modis" (+54 hits)
    -   "landsat" (+163 hits)
    -   *(other satellites?)*
-   Decision making context (all connected with OR)
    -   "decision" (+346)
    -   "optimiz\*" (+245)
    -   "risk analysis" (+9)
    -   "management" (+1951)
    -   "policy" (+278)
    -   "cost benefit analysis" (+18)
    -   "benefit cost analysis" (+1)
    -   "investment" (+50)
    -   "contingent valuation" (+9)
    -   "counterfactual" (+0) - dropped
-   societal value - value clause AND social, ecological, economic clause
    -   Value context (all connected with OR)
        -   "value" (+2259)
        -   "valuation" (+83)
        -   "benefit" (+651)
        -   "utility" (+413)
        -   *maybe "quality" (+3577) or "assess" (+7792) or "evaluat*" (+5132) - NO, these blow it up too much
    -   AND
    -   Societal context (all connected with OR):
        -   "social" (+101)
        -   "societal" (+31)
        -   "cultural" (+38)
        -   "\*economic" (+393)
        -   "environmental" (+688)
        -   "ecosystem service" (+65)
        -   "sustainable development goal" (+5 hits)
        -   "protected area" (+10 hits)
        -   "heritage site" (+2 hits)
        -   "non use value" (+0 hits)
        -   *NASA Applied Science themes:*
        -   "capacity building" (+6)
        -   "disaster" (+185)
        -   "water resource\*" (+299)
        -   "climate resilience" (+2 hits)
        -   "air quality" (+52)
        -   "conservation" (+462)
        -   "wildland fire\*" (+8)
        -   "wildfire" (+55)

### Exploration of adding specific satellite names

On 12/4/23, I ran a search in Web of Science using the above terms (on this date, 4314 results were returned).  I then added in various specific satellites (in addition to MODIS and LandSat, already in the search term) to see how many new hits were generated.  Additionally, I tested the satellite name *on its own within the ESI Venn bubble*without* the term "satellite" to see how many hits it generated in isolation.

Satellite names tested:

* AVHRR (+4 hits, 36 in isolation)
* Sentinel (+196 hits, 416 in isolation)
* VIIRS (+10 hits, 31 in isolation)
* SeaWiFS (+ 0 hits, 5 in isolation)
* MISR (+0 hits, 1 in isolation)
* SRTM (+12 hits, 40 in isolation)
* ECOSTRESS (+0 hits, 3 in isolation)
* SMAP (+1 hit, 19 in isolation)
* GRACE (+51 hits, 84 in isolation)
* GRACE-FO (+1 hit, 2 in isolation)
* GOES- (+1194 hits, almost certainly mostly spurious; 1219 in isolation)
* NOAA-1 (+0 hits, 0 in isolation)
* SUOMI (+1 hit, 8 in isolation)
* Jason-3 (+0 hits, 1 in isolation)
* TERRA (+48 hits, 80 in isolation)

Consider adding any terms that increase hits by at least ten papers above and beyond "final search terms" noted above.  This adds:

* "GRACE" OR "SRTM" OR "Sentinel" OR "VIIRS" OR "TERRA"