---
title: "Phase 4: gather and prepare full texts for sample of predicted excludes"
author: "O'Hara"
format: 
  html:
    code-fold: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: source
---

```{r setup}
library(tidyverse)
library(synthesisr)
library(here)
```

# Summary

After running the classifier model, a sample of 1000 predicted "excludes" was put into colandr for screening.  The results were then used to gather full texts for a sample of the included papers - 11 with available full texts.  

# Data

The screening criteria outlined in the planning/protocol document were used to determine inclusion/exclusion.  Some documents were tagged with additional information, e.g., "maybe" for some included documents that seemed like they may not actually meet the criteria.

The screening results were downloaded as two .csvs (include, exclude) and combined using the script `_data/screened_colandr/colandr_phase_tag.R`.

# Methods

## Consolidate Colandr results

```{r}
col_by_phase_fs <- list.files(here('_data/screened_colandr'), 
                                 pattern = 'colandr_by_phase', full.names = TRUE)
dates <- str_extract(basename(col_by_phase_fs), '[0-9]{4}-[0-9]{2}-[0-9]{2}') %>% as.Date()

f <- col_by_phase_fs[dates == max(dates)]
                     
results_all_df <- read_csv(f, show_col_types = FALSE)

results_excl_df <- results_all_df %>%
  filter(phase == 'classifier excl sample')

```

## Isolate includes and save as .bib for Zotero

Write out dois as .csv, import into Zotero using the magic wand (add objects by identifier) to auto grab PDFs.  For ones that Zotero does not automatically find .pdfs, use Google Scholar to see if other pdfs are available.  If behind a paywall (inaccessible from UCSB library) or no DOI then the paper will not be included in the full text screening.

NOTES:

* Colandr seems to fuck up the author order by alphabetizing when exporting...
* Use VPN to log into UCSB account for more likely retrieval?

```{r}
key_df <- read_csv(here('_data/1c_refs_clean/ref_key_lookup.csv'))

incl_df <- results_excl_df %>%
  filter(screening_status == 'included' & !is.na(doi)) %>% 
  select(-screening_status, -year, -tags, -excl_reasons, -phase) %>% 
  mutate(doi = str_remove(doi, ' and .+')) %>% 
  left_join(key_df, by = c('title', 'doi')) %>% 
  as.data.frame()
  

to_zot_f <- here('_data/6_screen_classifier_excludes/bib_to_zotero_cls_excl_sample.bib')

if(!file.exists(to_zot_f)) {
  
  write_refs(incl_df, format = 'bib', 
             file = to_zot_f)
}
### to_zot_df <- read_refs(to_zot_f)
```


## Import full texts into Zotero

Pulling the DOI information from these papers, and importing into Zotero via the "add item(s) by identifier" option, downloads (where possible) the PDFs into a designated subcollection.  Checking the successfully downloaded DOIs against the full list, we can identify those references not found via DOI.

```{r}
zot_check <- read_refs(here('_data/6_screen_classifier_excludes/bib_from_zotero_cls_excl.bib')) %>%
  mutate(title_check = str_remove_all(tolower(title), '[[:punct:]]') %>% str_squish(),
         doi = tolower(doi))

pdf_find <- zot_check %>% filter(is.na(file))
```

Out of `r nrow(incl_df)` included papers, `r nrow(zot_check)` have records in Zotero; of these, `r nrow(pdf_find)` do(es) not have a .pdf available.

## Write out temp csv for full text screening

```{r}
fulltext_df <- incl_df %>%
  select(title, author, year, doi, key) %>%
  mutate(phase = 'classifier excludes',
         screening_decision = NA,
         reason_for_exclusion = NA,
         quick_notes = NA,
         soc_method = NA,
         societal_benefit = NA,
         value_units = NA,
         eo_data = NA,
         applied_science_theme = NA,
         notes = NA)

write_csv(fulltext_df, here('_data/screened_fulltext/5_tmp_classifier_excl.csv'))
```


