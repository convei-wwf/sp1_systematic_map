page,p
1,"hapter 4 gh resolution satellite image ientation models ia crespi, francesca fratarcangeli, francesca giannone, cesca pieralice ntroduction few years ago high resolution satellite imagery became available to a limited er of government and defense agencies that managed such imagery with y sophisticated software and hardware tools."
1,"such images became available vil users in 1999 with the launch of ikonos, the first civil satellite offering a al resolution of 1 m."
1,"since then other high resolution satellites have been hed, among which there are eros-a (1.8 m), quickbird (0.61 m), orbview- m), eros-b (0.7 m), worldview-1 (0.5 m) and geoeye-1 (0.41 m), with others being planned to launch in the near future."
1,high resolution satellite ery is now available in different formats and processing levels at an afford- price.
1,"the diverse types of sensors and their growing availability are revolu- ing the role of satellite imagery in a number of applications, ranging from in- ency to insurance, media, marketing, agriculture, utilities, urban planning, ry, environmental monitoring, transportation, real estate etc."
1,"as a possible ative to aerial imagery, high resolution satellite imagery has also impact in graphic applications, such as in orthophoto production, especially for areas e the organization of photogrammetric surveying may be critical. oreover, an increasing demand for large scale mapping and terrain modelling so that almost all the satellites have along-track stereo acquisition capabil- many new satellites dedicated to stereo viewing, for example cartosat-1 (2.5 ave been launched."
1,"this compensates the limited capacity of very high reso- n satellites for three-dimensional point determination and enables the genera- of digital elevation models (dems) and digital surface models (dsms), lso for 3d feature extraction (e.g. for city modelling). owever, the possibility of using high resolution satellite images for cartogra- depends on several factors: mapping specifications, sensor characteristics metric and radiometric resolution and quality), types of products made avail- by the companies managing the satellites, quality of the software used to pro- the cartographic products, and quality of the final results. t al. (eds.), geospatial technology for earth observation, 63 0.1007/978-1-4419-0050-0_4, nger science + business media, llc 2009"
2,is the sensor model being able to provide a high level geometric correction gh image orientation.
2,"the distortion sources can be related to two general ories: the acquisition system, which includes the platform orientation and ment, and the imaging sensor optical-geometric characteristics; the atmos- refraction, causing a remarkable deviation from the collinearity hypothesis rdlinger 1999). wo different types of orientation models are usually adopted: the physical r models (also called rigorous models) and the generalized sensor models."
2,"in rst ones, based on a standard photogrammetric approach where the image and round coordinates are linked through the collinearity equations and the in- d parameters have a physical meaning."
2,"besides, they require knowledge on pecific satellite and orbit characteristics."
2,"on the contrary, the generalized ls are usually based on the rational polynomial functions (rpfs), which image and terrain coordinates by the rational polynomial coefficients s) and do not need the knowledge about the sensor and acquisition features."
2,"rpcs can be calculated by the final users via a least squares (ls) estimation ly from ground control points (gcps), or proprietarily generated by the r managing companies based on their own physical sensor models and dis- ed to users through imagery metadata."
2,"nevertheless, the first strategy (also d terrain-dependent) is not recommended if a reliable and accurate orientation uired."
2,"in the second strategy, they can be generated according to a terrain- endent scenario, using known physical sensor."
2,"in order to avoid instability o high correlations among the coefficients, two different methods can be tichonov regularization or an innovative method based on singular value mposition (svd) and qr decomposition, estimating only the strictly re- d coefficients. is chapter will discuss many features of the sensor models, both for single es and stereopairs."
2,"specifically, discussions will be focused on the rigorous l for the orientation of the basic image (level 1a) (sect."
2,"4.2, 4.3, 4.6) and of mage projected to a specific object surface (usually an expanded ellipsoid de- from the wgs84) (level 1b) (sect."
2,"the rpc model for the orientation ngle and stereopairs images is discussed in sections 4.7, 4.8."
2,"section 4.9 ad- es the methods for accuracy assessment, while section 4.10 presents applica- xamples of different sensor modelling."
2,"rigorous models e rigorous model is based on a standard photogrammetric approach, i.e., the earity equations describing the physical-geometrical image acquisition."
2,"it consider that an image from a pushbroom sensor is formed by many (from ands to tens of thousands) individual lines, each acquired with proper posi- projection center) and attitude values."
2,all the acquisition positions are related
3,"of the orbital segment during image acquisition through the knowledge of the sition mode, sensor parameters, satellite position and attitude parameters. pproximate values of these parameters can be computed by using the infor- n contained in the image metadata file, delivered with each image."
3,these ap- mate values are then corrected by a ls estimation process based on a suitable er of gcps.
3,"moreover, in order to relate the images to the ground coordi- expressed in an earth centered - earth fixed (ecef) reference frame, a ation and a set of rotation matrices depending on orbital parameters (keple- elements) and sensor attitude have to be used."
3,"these matrices include those ed to shift between sensor, platform, orbital and earth centered inertial (eci) inate systems, while the transformation between eci and ecef coordinate ms must take into account precession, nutation, polar motion and earth rota- matrices (kaula 1966)."
3,"1 coordinate systems order to introduce the collinearity equations, the definitions of some coordi- ystems are needed (westin 1990): mage system (i): is a 2-dimensional system describing a pixel position in an e."
3,"the origin is in the upper left corner, and the pixel position is defined by w (j) and column (i)."
3,the column numbers increases toward the right and umbers increases downwards (fig.
3,"4.1a). nsor system (s): the origin is at the perspective center (whose orbital motion be described as if it were the satellite center of mass), the z-axis is directed the perspective center to pixel array, the x-axis is approximately tangent to rbit directed as the satellite motion (see paragraph 4.2.4, 4.2.5), and y-axis s a right-handed cartesian system."
3,note that y-axis is approximately parallel pixel array.
3,the principal point is the orthogonal projection of the perspec- enter onto the pixel array (fig.
3,4.1b).
3,perspective centre 0.5 1.5 ys i 0.5 xs 1.5 zs α β f i j j pixel array (a) (b) fig.
3,4.1 image system (a) and sensor system (b)
4,"ϕ), pitch (θ) and yaw (ψ) are zero. ight system (f): the origin is at the perspective center, the x-axis is tangent orbit along the satellite motion, the z-axis is in the orbital plane towards the center of mass and the y-axis completes the right-handed coordinate system. rbital system (o): the xo-yo plane coincides to the orbital plane, which is ed by right ascension of the ascending node (ω) and by the orbit inclination -axis is along the nodal line, y-axis and z-axis complete the right-handed co- ate system."
4,"with the hypothesis of keplerian orbit, z-coordinate of satellite orbital system is zero. arth centered inertial system - eci (i): the origin is at the earth center of the x-axis points to vernal equinox (epoch j2000 - 1 january 2000, hours 12 the z-axis points to celestial north pole (epoch j2000) and the y-axis com- s the right-handed coordinate system (teunissen and kleusberg 1998, hof- et al."
4,"2008). arth-centered earth-fixed system — ecef (e): the origin is at the earth r of mass, the x-axis is the intersection of equatorial plane and the plane of ence meridian (epoch 1984.0), the z-axis is the mean rotational axis (epoch 0) and the y-axis completes the right-handed coordinate system (teunissen kleusberg 1998, hofmann et al."
4,"2008). eodetic local system (l): the origin is a chosen point on the ellipsoid (here wgs84 is used) the n-axis is tangent to the local meridian, e-axis is tangent to cal parallel and h-axis (elevation axis) is along the ellipsoid normal."
4,2 orbital parameters he satellite orbit can be described using the well-known keplerian elements 4.2).
4,"according to keplerian laws, a satellite (considered as a material point), the effect of a gravitational field generated by a mass concentrated in a moves in a plane describing an elliptic orbit."
4,"the satellite position at each ic epoch t is represented by seven parameters (kaula 1966, westin 1990)."
4,zi yo ys satellite perigee v satellite b ω r equator e v ω apogee a earth perigee xs nodal line i centre xi yi ascending node xo fig.
4,4.2 keplerian parameters
5,bit inclination (i): it is the angle (positive if counter clockwise) between the al plane and the equatorial plane.
5,"by convention it is between 0 and π. ght ascension of the ascending node (ω): it is the angle (positive if counter wise observed from the north pole) at the center of the earth from the vernal ox to the ascending node. centricity (e): it is the eccentricity of the orbital ellipse. ue anomaly (v): it is the angle measured in the center of the ellipse between erigee and the position of the satellite at generic epoch t defined to be 0 at ee. gument of the perigee (ω): it is the angle between the nodal line (intersec- between the orbital plane and the equatorial plane) and the semi-major axis, ured in the orbital plane from the ascending node to the perigee. me of the perigee passage (tp): it is the time referring to the epoch when the ite is nearest to the earth. e approximate values of these parameters can be computed based on the meris information in the metadata file released together with the image. some cases (e.g."
5,"ikonos, quickbird standard orthoready, cartosat-1), the data file released by the sensor managing companies do not include the meris file (spacecraft position and velocity every few seconds) but only one ite mean position that is described by two angles: imuth (α): it specifies the satellite position relative to the area that is col- d on earth, it is measured clockwise from the north. evation (e): it is the angle from the horizon up to the satellite. evertheless, some main features of the orbit (a, i) are always known, so that pproximate values of the other keplerian elements may still need to be com- ."
5,"3 attitude angles define the sensor during the acquisition it is necessary to know its attitude ibed by the roll (ϕ), pitch (ϑ) and yaw (ψ) angles, respectively referred as x, axes of the flight system."
5,the approximate values of these angles are calcu- with the metadata file information.
5,the corrections to these approximate val- may be modeled by second order polynomials.
5,"although there is not any cal meaning in doing this, good results seem to support this choice (westin ) ⎧ϕ = ϕ~ + a + a τ + a τ 2 0 1 2 ⎪⎪ ~ 2 ⎨ϑ = ϑ + b0 + b1τ + b2τ (4.1) ⎪ψ = ψ~ + c + c τ + c τ 2 ⎩⎪ 0 1 2"
6,a row on the ground and js is the row of the pixel.
6,"the nine coefficients (ai, are unknown and need to be estimated with the ls adjustment. some case (e.g."
6,"ikonos) the satellite can acquire images at a stated scan azi- (the exact angle from the starting point of the scan and it is measured clock- from north) and following a stated scan direction (“forward” or “reverse”); a se scan is generally from north to south, whereas a forward scan being from h to north."
6,i north north scan azimuth 180° scan azimuth 90° j js js fig.
6,"4.3 example of js-axis direction the scan azimuth is 180° and the scan direction is “reverse”, the image is col- d from north to south, or if scan azimuth is 90° and the scan direction is ward”, the image is collected from west to east."
6,"in the former case, the j-axis age system is directed to the scanning direction, whereas in the latter the ing direction is perpendicular to the j-axis of the image system (fig."
6,"so osition of a generic point p (i, j) has to be projected on scanning direction (js- with the following relation: j s = − j ⋅ cos β + i ⋅ sin β (4.2) e β is the scan azimuth and i, j are the image coordinates."
6,4 coordinate system transformations e global rotation matrix from the sensor system to the eci can be expressed gh three rotations (westin 1990) rsi = rfi ⋅ rbf ⋅ rsb (4.3) h can be detailed recalling the standard from the matrices representing the ro- s around the axes of the right-handed cartesian coordinate system:
7,"⎢⎣0 − senα cos α ⎥⎦ ⎢⎣ senβ 0 cos β ⎥⎦ ⎢⎣ 0 0 1⎥⎦ ions α, β, γ are positive if they are counter clockwise when seen from the ve semi axes). ertial-orbital matrix (roi): this allows the passage from inertial geocentric m (eci) to the orbital one."
7,it is a function of right ascension of ascending (ω) and of orbit inclination (i) roi = r x (i) ⋅ rz (ω) (4.5) ertial-flight matrix (rfi): this allows the passage from the inertial geocen- ystem (eci) to the flight one.
7,"it is a function of keplerian orbital parameters aries with the time inside each scene (for each image row j) π π rfi = r x (− ) ⋅ rz ( ) ⋅ rz (u ) ⋅ r x (i) ⋅ rz (ω) (4.6) 2 2 e i is the inclination, ω the right ascension of the ascending node, u = ω + v ω argument of the perigee and v true anomaly ight-body matrix (rbf): it allows the passage from the orbital system to the one through the attitude angles (ϕ, ϑ, ψ), which depends on time (for each row) rbf = rz (ψ ) ⋅ ry (ϑ ) ⋅ r x (ϕ ) (4.7) ody-sensor matrix (rsb): it allows the passage from the body to the sensor m."
7,"this matrix considers the deviation of the parallelism between axes z)s and (x,y,z)b and it is considered constant during a scene for each sensor. ements may be provided in the metadata files. e rotation matrix for the transformation from eci system to ecef system can be subdivided into four sequential steps, considering the motions of the in space: precession, the secular change in the orientation of the earth's rota- axis and the vernal equinox (described by the matrix rp); nutation, the peri- and short-term variation of the equator and the vernal equinox (described by matrix rn); polar motion, the coordinates of the rotation axis relative to the reference pole (described by the matrix rm); and earth's rotation about its (described by the sideral time through the matrix rs) (montenbruck gill )."
7,"rei = rm ⋅ rs ⋅ r n ⋅ rp (4.8) product of rei and rsit matrices allows the passage from sensor s to ecef m, with the final rotation matrix being:"
8,"e the angles (k, p, w) define the satellite attitude at the epoch of the acquisi- f image row j with respect to the ecef system."
8,5 interior orientation and self-calibration parameters e interior orientation parameters describe the intrinsic geometric features of ensor.
8,"moreover, self-calibration parameters are used to correct the geometric s in the ccd linear array and the optical system."
8,"note that, referring to the array design, one ccd line can be made of ns segments being npi is the er of pixels contained in i-th segment."
8,the modeling of the geometric errors y if carried out in the sensor system (s).
8,"for the sake of simplicity, here we der models under the assumption of ns = 1 ."
8,more details may be found in 2005).
8,1 ccd linear array geometric errors e geometric errors that may occur in ccd linear array sensors are briefly de- ed and modeled hereafter: e change of the pixel size.
8,it has the effect to change the image scale (fig.
8,"4). (px, py) are the pixel dimensions and (dpx, dpy) a change of the pixel size in x ion and in y direction respectively, the errors (dxp, dyp) result: dp y dx p = dp x dy p = y ⋅ (4.10) py error dyp may be also due to the focal length variation and the radial distor- note that the first order terms in 4.10, 4.13 are highly correlated."
8,"therefore, not possible to estimate both the pixel dimension variation together the focal h variation. ys xs fig."
8,4.4 effect of pixel size change in ys direction “from (poli 2005)” e shifts and rotations of the ccd segments in the focal plane.
8,these errors e described and modelled as follows:
9,ectively dyc ys ys dxc xs xs 5 shift of ccd segment in ys direction (a) and shift of ccd segment in xs direction (b) (poli 2005)” ect of horizontal rotation θ in the ccd plane.
9,the rotation produces the error θ in ys direction and dxθ in xs direction (fig.
9,"4.6), but only the latter has to be nsidered since θ is small: dxθ = y ⋅ sin θ (4.11) dyθ p' p'' ys θ dxθ xs p fig."
9,4.6 effects of rotation of ccd segment in the focal plane “from (poli 2005)” e line bending in the focal plane.
9,"the straight ccd line is supposed to be de- rmed into an arc if the size of the bending is described by the central angle δ at subtends the arc described by the deformed line and the central angle δ’ is ated to the generic pixel position, the error results fig."
9,"4.7, dxδ' 1/2(nppy) p' p'' ys xs δ' r δ c fig."
9,4.7 line bending in the focal plane “from (poli 2005)”
10,"δ s 2 sen 2 ⎛ δ⎞ dxδ ' = r⎜ cos δ ' − cos ⎟ (4.12) ⎝ 2⎠ ccd line is bending in the plane where xs < 0 , equation (4.12) is valid he opposite sign."
10,"2 optical system errors e possible errors that may occur in an optical systems have been deeply in- gated in close range, airborne and satellite photogrammetry (brown 1971, r 1992, jacobsen 1998). e displacement of the lens principal point."
10,"this error is modelled with con- nt shifts δxp, δyp applied to the principal point coordinates (xp, yp) in x and y ections and is totally correlated with the shift of the ccd linear array in the cal plane. e change of the focal length f."
10,the effect of this error δf in x and y directions modeled as δf dx f = − ⋅ xp f (4.13) δf dy f = − ⋅ yp f e x p = x − x p and y p = y − y p . e symmetric lens distortion is described by the coefficients k1 and k2 and odelled as ( ) dxr = k1 ⋅ r 2 + k 2 ⋅ r 4 ⋅ x p dyr = (k1 ⋅ r 2 + k 2 ⋅ r 4 )⋅ y p (4.14) e r 2 = x 2p + y 2p .
10,for pushbroom sensors with ccd linear array only dyr may gnificant and r 2 ≅ y 2p . e decentering lens distortion is modeled as
11,"(4.15) dyd = 2 p1 ⋅ x p y p + p2 ⋅ r 2 + 2 y 2p n, only dyd may be significant."
11,"3 final consideration about the self-calibration parameters ccounting for the described general models for the ccd linear array geomet- rors and for the optical system errors and considering their significance and lations, only a few self-calibration parameters need to be introduced."
11,"more- these parameters can be conveniently chosen to directly model self- ation with respect to the image coordinates (i, j)."
11,"in detail, the following alibration parameters are worth to be set up: the position of principal point (i0, j0), accounting also for the shift of the ccd linear array in the focal plane (as described in fig."
11,the rotation of the ccd linear array in the focal plane (k) (as described in fig.
11,"the change of the focal length (δf), accounting also for the scale variation and the isotropic change of pixel dimension."
11,"the symmetric lens distortion up to the third order in y direction only (d2) nother possible parameters is δ representing the line bending, however, it will e considered in the following rigorous model implementation."
11,"rigorous model for original images (level 1a) mentioned before, a rigorous model is based on the collinearity equations escribes the imagery acquisition both from the geometrical and physical (and astic) points of view."
11,"it is now possible to write the collinearity equations re- to the position of a point in the image space to the corresponding point in bject space, according to a central projection."
11,"in our case, the collinearity ions may be conveniently expressed in the earth centered inertial (eci) sys- tarting from the relationship (fig."
11,"4.8) ⎡xt ⎤ ⎡x s ⎤ ⎡u x ⎤ ⎡u x ⎤ ⎡xt − x s ⎤ ⎢ y ⎥ = ⎢ y ⎥ + d ⎢u ⎥ ⇒ ⎢u ⎥ = 1 ⎢ y − y ⎥ (4.16) ⎢ t⎥ ⎢ s⎥ ⎢ y⎥ ⎢ y⎥ d ⎢ t s ⎥ ⎢⎣ z t ⎥⎦ ⎢⎣ z s ⎥⎦ ⎢⎣ u z ⎥⎦ ⎢⎣ u z ⎥⎦ ⎢⎣ z t − z s ⎥⎦ e (xt, yt, zt)i are the eci coordinates of the ground point, (xs, ys, zs)i are the coordinates of the perspective center, (ux, uy, uz)i are the components in the"
12,"distance from the perspective center to the ground point. d= ( x t − x s )2 + (yt − ys )2 + (z t − z s )2 (4.17) zi perspective centre m(xs,ys,zs) orbit ys (xs,ys,f ) f xs s d· û yi ground point m'(xt,yt,zt) t earth centre xi of mass fig."
12,"4.8 central projection mode efore, introducing the sensor system the collinearity equations read: ⎡ xs ⎤ ⎡u x ⎤ ⎡ xs ⎤ ⎡xt − x s ⎤ 1 ⎢ ⎥ y s = rsi ⎢⎢u y ⎥⎥ ⇒ ⎢ y ⎥ = ds r ⎢ y − y ⎥ (4.18) ds ⎢ ⎥ ⎢ s ⎥ d si ⎢ t s ⎥ ⎢⎣ f ⎥⎦ ⎢⎣ u z ⎥⎦ ⎢⎣ f ⎥⎦ ⎢⎣ z t − z s ⎥⎦ i i e f is the focal distance, rsi is the rotation matrix from eci to sensor system s is the perspective center to image point distance d s = xs2 + y s2 + f 2 (4.19) ly, the standard form of two collinearity equations for each ground point is ned by dividing the first two equations of (4.18) by the third one: ⎧ xs rsi ,11 x t − x s + rsi ,12 yt − ys + rsi ,13 z t − z s ⎪ = ⎪ f r si ,31 x t − x s + rsi ,32 yt − ys + rsi ,33 z t − z s ⎨ (4.20) ⎪ y s = rsi ,21 x t − x s + rsi ,22 yt − ys + rsi ,23 z t − z s ⎪ f rsi ,31 x t − x s + rsi ,32 yt − ys + rsi ,33 z t − z s ⎩"
13,"ritten as a function of image coordinates, interior orientation and self- ation parameters previously set up, keplerian orbital and attitude parameters. ⎧ xs d pix ⎪ = tan β = [j − int(j ) − 0.5 − j 0 − k (i − i 0 )] ⎪f f (4.21) ⎨ ⎩⎪ f d f { ⎪ ys = tanα = − pix (i − i ) + d (i − i )3 + k[j − int(j ) − 0.5 − j ] 0 2 0 0 } efore, equating (4.20) and (4.21) the relationship between the image and the nd coordinates is found: d pix f1 = [j − int( j ) − 0.5 − j 0 − k ( i − i 0 )] + f rsi ,11 x t − x s + rsi ,12 yt − ys + rsi ,13 z t − z s − =0 rsi ,31 x t − x s + rsi ,32 yt − ys + rsi ,33 z t − z s (4.22) f2 = − d pix f {(i − i 0 ) + d 2 (i − i 0 ) 3 + k [j − } int( j ) − 0.5 − j 0 ] + rsi ,21 x t − x s + rsi ,22 yt − ys + rsi ,23 z t − z s − =0 rsi ,31 x t − x s + rsi ,32 yt − ys + rsi ,33 z t − z s e collinearity equations depend on the parameters described in the para- s 4.2.2, 4.2.3 and 4.2.5."
13,"in some cases the image metadata file is not supplied the satellite position and velocity at every interval time; thereby the orbit is structed using the procedure described in paragraph 4.4.1 (crespi et al. b). mentioned, the approximate values for all parameters may be derived from nformation contained in the metadata files, released together with the image ω, e, v, ω, ϕ, ϑ, ψ, f and i0) or they are simply fixed to zero (ai, bi, ci, j0, k 2)."
13,"in theory, these approximate values must be corrected by an estimation ss based on a suitable number of gcps, for which the collinearity equations ritten."
13,"nevertheless, since the orbital arc related to each image acquisition is mely short (a few hundreds of kilometers) compared to the whole orbit length of thousands)."
13,"some keplerian parameters are not estimable at all (a, e, ω) thers (i, ω, tp) are extremely correlated both among themselves and with re- to the sensor attitude, interior orientation and self-calibration parameters (f, k, d2) (giannone 2006)."
13,"the parameters estimable are (ai, bi, ci, tp, f, i0, j0, ."
13,"regarding the stochastic model, the standard deviations of the image obser- ns are set equal, since manual measurement tests carried out independently fferent operators range from 1/3 to 1/2 pixel in accuracy."
13,for the gcp coor- es standard deviations are usually set equal to the mean values obtained dur- eir direct surveying or cartographic selection (brovelli et al.
13,2008).
14,heric refraction effect causes a well know bending of the optical paths due to ariation of atmospheric density (fig.
14,4.9a).
14,"the purpose of atmospheric re- on modeling is the correction of the image coordinates in order to remove the ction effect and to estimate the orientation parameters under the hypothesis of ht optical paths, which are actually modeled by collinearity equations (4.22). ct, the ground point p is projected onto the image along a refracted path in p′, quations (4.22) model the collinearity condition along the straight path pop. efore, we need to compute the correction from p′ to p in order to properly the model (4.22)."
14,the deviation from the collinearity assumption due to the spheric refraction is computed by a model duly described in (noerdlinger ) (fig.
14,"4.9b, table 4.1) which basically allows to calculate the displacement d o the refraction effect and the position of p′ on the ground, starting from the adir angle."
14,"therefore, a first rough orientation is performed, neglecting the ction effect, in order to estimate the off-nadir angle under which each ground is imaged, then the corresponding p′. image coordinates correction (from p' to p) p (ip, jp) e p' (ip', jp') z' image plane z0 o p d p' rue optical path straight optical path (refracted) r (modeled by collinearity z0 equations) d p' p ground (a) (b) fig."
14,"4.9 effect of atmospheric refraction oreover, through the collinearity equations, starting from p and p′, the corre- ding image position p and p′ are computed, so that the components of the vec- suitable to remove the atmospheric refraction effect from the image coordi- can be computed by: ⎡ ia ⎤ ⎡ i p − i p' ⎤ ⎢j ⎥ = ⎢j − j ' ⎥ (4.23) ⎣ a ⎦ ⎣⎢ p p ⎦⎥ vector a is applied to the coordinates collected on the image, from which a estimation process is performed in order to refine the orientation parameters. that one iteration is usually enough, since the refraction is well estimated on asis of the first rough orientation."
15,"(a) (b) 10 distribution of atmospheric refraction effect, represented by vector a computed for round point mportant to consider the refraction effect especially when the satellite atti- variation during the image acquisition causes a refraction effect not uniformly buted (fig."
15,4.10a).
15,"on the contrary, its impact is lower when the satellite atti- variation causes a rather uniform refraction effect (fig."
15,4.10b).
15,"4.1 displacement d over the local sphere approximating the ellipsoid due to refraction ef- nction of z0 z0 (°) z' (°) z0 - z' (°) d (m) 10 9.99710 0.0029 0.47 20 19.9939 0.0061 1.06 30 29.9904 0.0096 1.97 40 39.9860 0.0140 3.62 45 44.9834 0.0166 5.03 50 49.9802 0.0198 7.21 order to avoid instability due to high correlations among some parameters ng to design matrix pseudo-singularity, singular value decomposition (svd) qr decomposition are employed to evaluate the actual rank of the design ma- o select the actually estimable parameters and finally to solve the linearized earity equations system in the ls sense (see sect."
15,"moreover, the statis- significance of each estimable parameter is checked by a student t-test so to over-parameterization."
15,"in case of a statistically non-significant parameter, it moved and the estimation process is repeated until all parameters are signifi-"
16,"acy, which may vary depending on their source (cartography or direct sur- g). orbit satellite (xs, ys, zs) los hs ground point (xt, yt, zt) ground image point (xi, yi, zi) inflated ellipsoid h_ref ellipsoid fig."
16,"4.11 model geometry rigorous model for pre-processed images (level 1b) this case it has to be noted that the images are projected onto a specific ob- usually an “inflated” ellipsoid, derived from the wgs84 choosing a certain oidal height) (level 1b)."
16,"the collinearity equations link points on the ground oints projected on the mentioned “inflated” ellipsoid (pieralice 2007, see fig. . ch point on the ground surface corresponds to a point on “inflated” ellipsoid, fied from line of sight (los), i.e. the line directed from the perspective cen- the point on the ground."
16,"the collinearity condition is satisfied when û si unit vector directed from perspective centre to image point) coincides with (the unit vector directed from perspective centre to ground point), i.e., nd point and image point are lined up on los."
16,the collinearity equations may nveniently expressed in the ecef system in vector form: uˆ si = r ⋅ uˆ st (4.24) e r is a rotation matrix.
16,"in fact, relative “small” translation of ground with re- to ellipsoid can be expressed with an infinitesimal rotation around the per-"
17,"ence of elevation between ground surface and the “inflated” ellipsoid (δh). nder this infinitesimal rotation hypothesis ( cos ϕ , θ ,ψ ≅ 1 , ≅ ϕ , sin θ ≅ θ , sinψ ≅ ψ ) the rotation matrix r is reduced to the sum of the matrix and an anti-symmetric matrix. ⎡ 0 ϕ θ⎤ ⎡ 1 ϕ θ⎤ ~ r = r + δr = i + δr δr = ⎢⎢− ϕ 0 ψ ⎥⎥ ⇒ r = ⎢⎢− ϕ 1 ψ ⎥⎥ (4.25) ⎢⎣ − θ − ψ 0 ⎥⎦ ⎢⎣ − θ − ψ 1 ⎥⎦ e the attitude angles are supposed to be modelled by a time-dependent func- up to the second order, similar to (4.1)."
17,"the (4.24) can also be expressed in llowing way: ⎡x i − x s ⎤ ⎡ xt − x s ⎤ ⎢ y − y ⎥ = ρr ⎢ y − y ⎥ (4.26) ⎢ i s ⎥ ⎢ t s ⎥ ⎢⎣ z i − z s ⎥⎦ ⎢⎣ zt − z s ⎥⎦ e ρ is the scale factor, (ratio of perspective centre-image point distance dsi and perspective centre-ground point distance dst: ρ = d si d st ; xt, yt, zt are the ground coordinates in the ecef system; xi, yi, zi are the image coordinates in the ecef system; xs, ys, zs are the perspective centre coordinates in the ecef system. ly, note that in this case the collinearity equations on the basis of previous deration, now reads ⎧ xi − xs rse ,11 x t − x s + rse ,12 yt − ys + rse ,13 zt − z s ⎪ f1 = − =0 ⎪ zi − zs rse ,31 x t − x s + rse ,32 yt − ys + rse ,33 zt − z s (4.27) ⎨ ⎪ f = yi − ys − rse ,21 x t − x s + rse ,22 yt − ys + rse ,23 zt − z s = 0 ⎪ 2 zi − zs rse ,31 x t − x s + rse ,32 yt − ys + rse ,33 zt − z s ⎩ e collinearity equations depend on the parameters described in paragraphs and 4.2.3."
17,"the approximate values for all parameters may be derived from nformation contained in the metadata files, released together with the image e, i, ω) or they are simply fixed to zero (ai, bi, ci)."
17,"again, these approximate s must be corrected by an estimation process based on a suitable number of s, for which the collinearity equations are written."
17,"finally, the parameters es- le are (ai, bi, ci). has to be noted that the image coordinates in the collinearity equations (4.27) be expressed in the ecef system, while on the other hand the image coordi- are obtained by point measurement on the image so that only i and j are n."
18,"hrough the simple equations: ⎧n p = n a − j ⋅ p ⎨ (4.28) ⎩ep = e a + i ⋅ p e np, ep are the north and east utm wgs84 coordinates of a generic point p."
18,"na, ea are the north and east utm wgs84 coordinates of upper left corner a of the image."
18,"i, j are the coordinates of a generic point p in the image system. p is the pixel size (in meters). oreover, the cartographic coordinates are converted into geographic coordi- (latitude ϕ and longitude λ)."
18,"finally, since the ellipsoidic height (h) of points e image is the elevation of “inflated” ellipsoid, the geodetic coordinate (ϕ, λ, converted in cartesian coordinates (ecef system)."
18,"1 computation of satellite positions general the detailed information about the satellite position are not supplied e level 1b images, therefore the satellite coordinates can be computed only e basis of the angles (azimuth and elevation) that define satellite position with ct to image center (fig."
18,4.12).
18,s γ b h e c h_ref inflated ellipsoid ellipsoid r ω fig.
18,4.12 satellite position with respect to image center
19,r c and the satellite position s are calculated with the sine theorem.
19,"( r + h _ ref ) ⋅ sin(e + π / 2) sin γ = (4.29) (r + h ) ( r + h _ ref ) ⋅ sin ω b= (4.30) sin γ e r is the radius of local sphere, h is the height of satellite, h_ref is the height nflated” ellipsoid in reference to the wgs84 ellipsoid, e is the elevation an- is the off-nadir angle and ω = π − (γ + e + π / 2) ."
19,"the satellite coordinates in detic local system, whose origin is the center of image (c) are: ⎧ x s (c ) = b ⋅ cos e ⋅ sin α ⎪ ⎨ys (c ) = b ⋅ cos e ⋅ cosα (4.31) ⎪z ⎩ s (c ) = b ⋅ sin e cal coordinates are transformed into ecef coordinates, and from the unique ite position it is possible to reconstruct the orbit segment."
19,"satellite coordi- are converted from ecef to eci system (4.8), then from eci to the orbital m with roi matrix (4.5). enerally the inclination i is known, on the contrary the right ascension of as- ng node ω can be calculated under the hypothesis of keplerian orbit it = 0 )."
19,"this equation has two solutions (ω1, ω2) that correspond to ascending escending orbit respectively."
19,"if the satellite moves on descending orbit while res images, the right value of ω is obtained with x s (c ) < 0 (abscissa in the al system), otherwise the solution is with x s (c ) > 0 if the satellite is ascend- n the orbital plane the satellite position relative to image’s center (s(c)) identi- he uc angle, where u c = arctan(ys (c ) / x s (c ) ) ; consequently the satellite on relative to each image row is obtained, moving the satellite forward and ward on the orbit with respect to central position: u i = u c − ( jsc − jsi ) ⋅ δu (4.32) e jsc is the scanning row of image’s center, and jsi is a generic scanning row image and δu is the angular displacement relative to one scanning row."
19,atr δu = (4.33) r + h _ ref atellite position (si) in the orbital system is:
20,⎪ ⎨ys (i ) = ( r + h ) ⋅ sin u i (4.34) ⎪ ⎪⎩z s (i ) = 0 e r is the radius of local sphere and h is height of satellite platform (fig. .
20,then the satellite coordinates must be converted into the eci system and he ecef system.
20,the ecef coordinates enter in collinearity equations.
20,"computation techniques as mentioned, the design matrix is likely to be close to singularity, so that estimation and estimable parameter selection is mandatory."
20,"in this respect and qr decomposition are quite useful tools and they will be shortly recalled the singular value decomposition (svd) and the qr decomposition are oyed to solve the linearized collinearity equations system in the ls sense ng and borre 1997, golub and van loan 1993)."
20,"as usual, the solution is ob- d iteratively due to non-linearity of the system; the iterative procedure stops the estimated variance of the unit weight observation stabilizes."
20,1 singular value decomposition e singular value decomposition (svd) is a very powerful technique to deal sets of equations or matrices that are either singular or numerically very close ing singular.
20,"the svd of a matrix a ∈ ℜ m⋅n (with m ≥ n ) is any factoriza- f the form: a = uwv t (4.35) ( ) e w ∈ ℜ n⋅n is a diagonal matrix with positive or zero elements wij that are ngular values of a; u ∈ ℜ m⋅n and v ∈ ℜ m⋅n are orthogonal matrices, whose ( ) mns u j , v j are called the left and right singular vectors."
20,"for a system of lin- quations ( ax = b ) , using the svd we can write (golub and van loan 1993): uwv t x = b (4.36) 2 he ls solution x minimizes ax − b 2 ."
20,"since the orthogonal matrix pre- s the norm, for any x ∈ ℜ n we have:"
21,2 2 2 e z = v t x and r is the rank of a.
21,"ax − b 2 = min holds, if r ∑ ( wi zi − uit b) 2 = 0 (4.38) i =1 using the svd, the ls problem is now in form of a diagonal matrix, and fi- ⎧ ut b ⎪ x = i vi if wi ≠ 0 (4.39) xi = ⎨ i wi ⎪undetermined if w = 0 ⎩ i advantage of using the svd is that it can reliably handle the rank deficient as well as the full rank case."
21,"2 qr decomposition e qr decomposition of a matrix a ∈ ℜ m⋅n (with m ≥ n ) is given by: a = qr (4.40) e q ∈ ℜ m⋅m is an orthogonal matrix and r ∈ ℜ m⋅n is an upper triangular ma- f the rank of a is equal to n, the first n columns of q form an orthonormal for the rank(a)."
21,"thus, the calculation of the qr factorization is a way to ute an orthonormal basis for a set of vectors. e standard algorithm for the qr decomposition involves sequential evalua- of householder transformations."
21,"an appropriate householder matrix, applied given matrix, can zero all the elements, situated below a given element, in a mn of the matrix."
21,"for the first column of the matrix a, an appropriate matrix evaluated, which puts on zero all the elements below the first element in the olumn of a."
21,"similarly h2 zeroes all elements in the second column below the d element and so on up to hn-1 r = h n −1 l h1 a (4.41) e qt = h n −1k h1 , i.e., q = h1 k h n −1 . e generic matrix hi zeroes all elements in the first column below the first ent for a sub-matrix of a ( ai ∈ ℜ((m −i )⋅(n −i )) )."
21,"if a is rank deficient, the qr rization does not give a basis for the rank(a)."
21,in this case to calculate an or-
22,"⎡r r12 ⎤ → r qt ap = ⎢ 11 ⎣ 0 0 ⎥⎦ → m−r (4.42) ↓ ↓ r n−r e p is a permutation, r is the rank of a, r11 is an upper triangular and non sin- matrix and q and p are products of householder matrices q = h1k h r , p1 k pr . r understanding the role of the permutation matrix, it is necessary to define ector n ∈ ℜ m for a generic matrix a ∈ ℜ m⋅n : a11 a12 l a1n a21 a22 l a2n amn = (4.43) m l m am1 l amn m m m n m = ∑ ak21 2 ∑ ak22 l ∑ akn (4.44) k =1 k =1 k =1 e element of the n are the square value of norm calculated for each column the permutation matrix p applied at the generic matrix a makes a matrix p such that the elements of the corresponding vector n are placed in de- ing order."
22,"as for the generic matrix hi, the generic matrix pi permutes the mn of a sub-matrix of ai ∈ ℜ((m −i )⋅(n −i )) ; if k is the column with the maxi- value of norm, the permutation matrix pi exchanges the columns i and k. a system of linear equations ( ax = b ) , if a ∈ ℜ m⋅n and has a rank r, the qr mposition produces the factorization ap = qr where r is described in the ion (4.41)."
22,as for the ls problem we have: 2 2 2 2 ax − b 2 = (qt ap)( pt x) − qt b = r11t − (c − r12 z ) 2 + d 2 (4.45) 2 e
23,"⎣z⎦ → n−r (4.46) ⎡c ⎤ → r qt b = ⎢ ⎥ ⎣d ⎦ → m−r a ls minimizer we have ⎡ r −1 (c − r z )⎤ x = p ⎢ 11 12 ⎥ (4.47) ⎢⎣ z ⎥⎦ a set of zeroes in this expression, we obtain the basic solution: ⎡ r −1c ⎤ x b = p ⎢ 11 ⎥ (4.48) ⎢⎣ 0 ⎥⎦ as at most r non-zero components and so ax b involves a subset of a col- ."
23,"3 subset selection using svd and qr r a system of linear equations ( ax = b ) , with a ∈ ℜ m⋅n (with m ≥ n ) it is sary to select the estimable parameters."
23,"we describe an svd-based subset ion procedure, due to golub, klema and stewart (golub and van loan ), that proceeds as follows: e compute the svd a = uwv t and use it to determine a rank estimate r th the qr decomposition qr = ap we select an independent subset of a lumns; if r11 x b = q t b with x b ∈ ℜ r and we set ⎡x ⎤ t = p⎢ b ⎥ (4.49) ⎣0⎦ a ⋅ t is an approximate ls predictor of b that involves the first r columns of the permutation matrix p is calculated so that the columns of the matrix ℜm⋅r in ap = [b1 , b 2 ] are “sufficiently independent” e predict b with the vector a⋅ t where t is described in the equation (4.49), d z minimizes b1 x b − b 2 ."
24,he rigorous model developed to orientate both level 1a and level 1b single can be extended to manage both along-track and across-track stereopairs pi et al. 2008a).
24,"in this case, it has to be noted that the orbital elements are me for two images if they were acquired during the same orbital path (along- stereopairs) or are different if the images are acquired during two different al paths at different epochs (across-track stereopairs). gain, the approximate values of these parameters can be computed by using formation in the metadata file and have to be corrected by a least square es- ion process based on a suitable number of gcps."
24,the estimable parameters e selected using the procedure described in section 4.5.
24,"in this respect, since e points may be conveniently considered, it is necessary to establish a proce- for the computation of their approximate ground coordinates, which have to s estimated together with all other parameters. rst of all, the single scenes have to be separately oriented adopting the already ibed rigorous model."
24,this separated orientation has to be considered just as ximate ones; they have to be refined in a block adjustment possibly includ- uited tie points.
24,"in theory, the homologous rays should intersect, identifying a e ground point for each couple of homologous points chosen over the image. rtheless, errors remaining in the separate orientations cause the well known axes, so that homologous rays do not intersect and no ground point can be d by intersection."
24,"therefore, it is necessary to set up a rule to compute the ap- mate tie point ground positions."
24,"to this aim, the choice was made to compute ositions of the two points on the homologous rays at minimal distance and o average their coordinates."
24,the minimum distance between the two rays is uted.
24,"the equations of two rays supposed straight can be written in paramet- rm x1 x 01 a1 x 2 x 02 a2 r1 : y1 = y01 + s ⋅ b1 r2 : y2 = y02 + t ⋅ b 2 (4.50) z1 z 01 c1 z2 z 02 c2 e (x0, y0, z0)1,2 are the coordinates of perspective centers in the ecef system e two images, (a, b, c)1,2 are direction cosine known from the separate orien- s."
24,"the condition to identify the two points on the rays at minimal distance : ⎧ ∂d 2 (s, t ) ⎪ =0 ⎪ ∂t ⎨ with d 2 (s, t ) = ( x 2 − x 1 ) 2 + (y2 − y1 ) 2 + ( z 2 − z1 ) 2 (4.51) ⎪ ∂d (s, t ) 2 ⎪ ∂s =0 ⎩"
25,fficients few years ago high resolution satellite imagery were available to a limited er of government and defence agencies that managed such imagery with y sophisticated software and hardware tools.
25,high resolution satellite im- are now available in different formats and processing levels and at an af- ble price.
25,"these types of sensors and their growing availability are revolu- ing the role of satellite imagery in a number of applications ranging from igency to insurance, media, marketing, agriculture, utilities, urban planning, ry, environmental monitoring, transportation, real estate etc. ne of the primary barriers to a wider adaptation and utilization of satellite im- is the sensor model being able to provide a high level geometric correction gh the image orientation."
25,"sensor models are a key component to represent the ional relationships between the image space and the object space, and are es- al for single/multi imagery orientation. en if the rigorous models should theoretically provide the highest accuracy, are only available for some satellites and can be managed by some commer- vailable software."
25,"moreover, in order to estimate the unknown parameters of ous models, users are still faced with the challenging task of recovering the or orientation of the sensor using a set of gcps usually no small than 10. n no or few gcps are available, users cannot recover the exterior orientation sensor and therefore are unable to perform various mapping and data collec- operations."
25,"with the introduction of generalized sensor models, this situation hanged considerably."
25,"generalized sensor models, such as the rpf (tao and 001a), have smoothed the requirement to manage a physical sensor model. ermore, as the rpc implicitly provides the interior and (approximate) exte- ensor orientation, the availability of several gcps is no longer a mandatory rement."
25,"consequently, the use of the rpc for photogrammetric mapping is ming a new standard in high-resolution satellite imagery that has already been mented in various high-resolution sensors, such as ikonos, quickbird and dview."
25,"1 rpc usage and orientation refinement mentioned before, some companies (for example digitalglobe for quick- and worldview and space imaging for ikonos, india space research or- ation for cartosat-1) usually supply the rpcs, as part of the image metadata able image orientation via rpf. e rpf relate object point coordinates (latitude, longitude and height) to pixel inates (i, j), as a physical sensor models, but in the form of ratios of poly- al expressions:"
26,"p2 (ϕ , λ , h ) p4 (ϕ , λ , h ) e ϕ, λ are the geographic coordinates, h is the height above the wgs84 ellip- and (i, j) are the image coordinates."
26,"the order of these four polynomials is ly limited to 3 so that each polynomial takes the generic form: m1 m2 m3 pn = ∑ ∑ ∑ tijk ϕ i λ j h k (4.53) i =0 j =0 k =0 0 ≤ m1 ≤ 3 ; 0 ≤ m2 ≤ 3 ; 0 ≤ m3 ≤ 3 and m1 + m2 + m3 ≤ 3 , where tijk are the rpc. e number of rpc depends obviously on the polynomial order: if the equa- (4.52) are written with third order polynomials, the maximum number of co- ents is 80 (20 for each polynomial)."
26,"actually, the total number of rpc is re- d to 78, because the two equations can be divided for the zero order terms of enominators. e great power of these equations is the independence from the physical char- stic of the image acquisition (nima 2000)."
26,"although ground coordinates are irectly connected with the acquisition physics, it is possible taking into ac- the further approximated considerations (tao and hu 2002): ratios of the order terms can represent distortions caused by the optical projection, while ctions such as earth curvature, atmospheric refraction and lens distortion can ell modelled by the second-order terms; other unknown and more complex tions with high-order components may be absorbed by the third-order terms. e ground coordinates (ϕ, λ, h) in the equation (4.52) are normalized to (-1, ange using normalization parameters supplied in the metadata file, in order to ove the numerical precision during the computation. e generic simple formula utilized for the normalization, is: t − toffset tn = (4.54) tscale e tn are the normalized coordinates, toffset, tscale are the normalization pa- ers available in the metadata file and t is the original ground or image coor- e (t=i, j; ϕ, λ, h). nce the residual bias may be present into the rpc, the orientation can be re- on the basis of the known gps, acting as gcps."
26,"a possible refinement of the l (4.52) (written in normalized coordinates), allowing for bias compensation, omplished in a quite common way with the introduction of a simple first or- olynomial in the rpf (4.55) whose parameters are estimated, provided a suit- number of gcps is known (hanley and fraser 2004, fraser and hanley )."
27,"a + a1λ n + a 2ϕ n + a3 hn + a 4 λ nϕ n + ... + a17 λ n 3 + a18ϕ n 3 + a19 hn 3 (4.55) + i n ⋅ a1 + j n ⋅ a2 + 0 1 + b1λ n + b2ϕ n + b3 hn + b4 λ nϕ n + ... + b17 λ n 3 + b18ϕ n 3 + b19 hn 3 p3 (ϕ n , λ n , hn ) o + j n ⋅ b1 + i n ⋅ b2 + = p4 (ϕ n , λ n , hn ) c + c1λ n + c 2ϕ n + c3 hn + c 4 λ nϕ n + ... + c17 λ n 3 + c18ϕ n 3 + c19 hn 3 + j n ⋅ b1 + i n ⋅ b2 + 0 1 + d1λ n + d 2ϕ n + d 3 hn + d 4 λ nϕ n + ... + d17 λ n 3 + d18ϕ n 3 + d19 hn 3 e (in, jn) are the normalized images coordinates, and pi are third order poly- al functions of object space normalized coordinates (ϕn, λn, hn); ai and bi describe image shift and drift effects in particular: a0, a1, a2, b0, b1, b2 describe a complete affine transformation."
27,"a0, a1, b0, b1 model the shift and drift."
27,"a0, b0, describe a simple coordinate shift. (a) (b) 13 example of residuals adjustment with an affine transformation on a quickbird image. rected image (a), corrected (b) e six new coefficients (ai, bi) are ls estimated based on gcps."
27,"it is noted n theory the model is not linear, since the 2nd and 3rd terms of the right side ve both observations (in, jn) and parameters (ai, bi)."
27,"nevertheless, usually in ght side observations in, jn are considered as fixed coefficients, so that the l is treated as linear with respect to the six coefficients (ai, bi) (fig."
27,"4.13a, )."
27,2 rpc generation e rpc can be generated by terrain-dependent scenario without using physi- ensor model (tao and hu 2001b) or according to a terrain-independent sce- using known physical sensor model.
28,"mage to 3d geometry represented by the gcps, the rpf model tries to ap- mate the complicated imaging geometry across the image scene using poly- al terms."
28,"the solution is highly dependent on the actual terrain relief, the bution and the number of gcps."
28,the rpcs have to be estimated in a ls ad- ent so that the number of gcps could be very high (at least 39 if rpc up to hird order are looked for).
28,this method is very weak and vulnerable in pres- of outliers and it is likely to cause deformations far from the gcps returning ood accuracies.
28,"therefore, the rpfs solved by terrain-dependent approach not be used as a replacement sensor model if high accuracy is required (tao hu 2001b, tao and hu 2001c, toutin et al. 2000) and will not be considered ore hereafter. r a terrain-independent scenario, a 2d image grid covering the full extent of mage is established and its corresponding 3d object grid with several layers four or more layers for the third-order case) slicing the entire elevation range nerated."
28,"the horizontal coordinates (x, y) of a point of the 3d object grid are lated from a point (i, j) of the image grid using the physical sensor model an a priori selected elevation z."
28,"then, the rpc are ls estimated with the ob- rid points and the image grid points."
28,this terrain-independent computational rio can make the rpf model a good replacement to the physical sensor mod- nd has been widely used to determine the rpcs. h=h3 h=h2 h=h1 wgs84 fig.
28,"4.14 grid for rpc generation in the terrain-independent approach has to be underlined that in the usually adopted terrain-independent approach, east square solution is often carried out through a regularization, since un- n rpcs may be highly correlated so that the design matrix is almost rank de- t (neumaier 1998)."
28,"in order to overcome the regularization requirements, an ative algorithm for the rpc extraction, with a terrain independent approach, lyzed."
28,"in details, at first an image discretization is made, dividing the full ex- mage space in a 2d grid."
28,"then, the points of the 2d image grid are used to"
29,"ous orientation sensor model, the collinearity equations were derived and to create the 3d grid, starting from each point of the 2d grid image."
29,"in this ct, it has to be underlined that the 2d grid is actually a regular grid, whereas d one is not strictly regular, due to the image attitude."
29,"moreover, the 3d grid s were generated intersecting the straight lines modelled by the collinearity ions with surfaces (approximately ellipsoids) concentric to the wgs84 ellip- placed at regular elevation steps."
29,"so, the dimension of the 3d grid is both on the full extent of the image and the elevation range of the terrain."
29,"the contains several elevation layers uniformly distributed, and the points on one have the same elevation value (fig."
29,"4.14). ote that the finest subdivision depends on the incompressible error of the rig- model used to generate the rpcs, so that a very fine discretization is unuse- d an upper discretization limit also exists."
29,"the rpcs least squares estimation and hu 2001c) is based on the linearization of the generic rpfs equations, h can be written as: 3 3 3 3 1λ n i n + b2ϕ n i n + ... + b18ϕ n i n + b19 hn i n − a0 − a1λ n − a 2ϕ n ... − a18ϕ n − a19 hn = 0 (4.56) d1λ n j n + d 2ϕ n j n + ... + d18ϕ n3 j n + d19 hn3 j n − c0 − c1λ n − c 2ϕ n ... − c18ϕ n3 − c19 hn3 = 0 e ai, bi, ci, di are the rpcs (78 coefficients for third order polynomials), (in, nd (ϕn, λn, hn) are the normalized coordinates obtained throughout the equa- 4.54), with scale and offset factors computed according to: ⎧woffset = min (wk ) ⎨ where w = ϕ, λ, h ⎩wscale = max (wk ) − min (wk ) ⎧ i offset = j offset = 1 (4.57) ⎪ ⎨ i scale = n°column − 1 ⎪j ⎩ scale = n°row − 1 e k is the number of available gcps and n° column/row are the overall col- /rows of the image; the normalization range is (0, 1). eeper investigations underlined that many rpcs are highly correlated."
29,"in or- o avoid instability due to high correlations, leading to a pseudo-singular de- matrix, tickhonov regularization is usually used."
29,"generally, the regulariza- s exploited in a tickhonov fashion, adopting a damping factor to the diagonal e normal matrix, in order to guarantee its non singularity."
29,a new alternative ach is based on the singular value decomposition (svd) and qr decompo- which are employed to evaluate the actual rank of the design matrix and to the actual estimable coefficients (bianconi et al.
29,"2008, brovelli et al. 2008); , the svd-based subset selection procedure is due to golub, klema and art (strang and borre 1997, golub and van loan 1993)."
30,pf model represents an attractive tool also for managing stereopairs orienta- nd possible subsequent dsm generation.
30,"also in this case, the first problem ve is the computation of terrain point’s approximate coordinates (ϕ, λ, h)."
30,a ht forward procedure is based on the direct linear transformation (dlt). near-linear projection of the high resolution satellite image ensures rapid con- nce of the spatial intersection from even very coarse initial values for the ob- oint coordinates. e dlt is not using any pre-information about image orientation.
30,the 22 un- ns (11 for each images) for the transformation of the object coordinates to mage coordinates have to be determined with at least 6 control points.
30,"the equations are: l ⋅ e + l2 ⋅ n + l3 ⋅ u + l4 i= 1 l9 ⋅ e + l10 ⋅ n + l11 ⋅ u + 1 (4.58) l ⋅ e + l6 ⋅ n + l7 ⋅ u + l8 j= 5 l9 ⋅ e + l10 ⋅ n + l11 ⋅ u + 1 e (i, j) are the image coordinates, (e, n, u) are the ground coordinates re- to the cartesian local system centered in the center of the image and the li he dlt parameters."
30,in case of stereopairs the equations (4.58) are doubled xpressed in the following forms for every gcp: ( ⎪ 9 10 11 ) ( ⎧ l1 e + l1 n + l1 u + 1 ⋅ i (1) − l1 e + l1 n + l1 u + l1 = 0 1 2 3 4) ( ⎪ 9 10 11 ) ( ⎪ l1 e + l1 n + l1 u + 1 ⋅ j (1) − l1 e + l1 n + l1 u + l1 = 0 5 6 7 8 ) (4.59) ⎨ ( 2 ⎪ l29 e + l10 2 n + l11 ) ( ) u + 1 ⋅ i ( 2) − l12 e + l22 n + l23u + l24 = 0 ( ) ( ) ⎪ ⎪ l2 e + l2 n + l2 u + 1 ⋅ j ( 2) − l2 e + l2 n + l2u + l2 = 0 ⎩ 9 10 11 5 6 7 8 e superscripts 1 or 2 are related to the first and the second image respectively.
30,"accuracy assessment of high resolution satellite imagery entation by leave-one-out method 1 hold-out validation urrently, the most used method to assess spatial accuracy of oriented high ution satellite image is the hold-out validation (hov), also known as test le estimation."
30,"according to it, the data set (known ground points) is parti- d in two subsets: the first one used to determine the orientation- rectification model (gcps) and the second to validate the model itself (check s or cps)."
30,the only restriction on such selection is to have both sets suffi-
31,n should be random.
31,"once the model is trained, accuracy is usually evaluated ot mean squared error (rmse) of residuals between imagery derived coor- es with respect to cps coordinates, independently determined and used as ence. is method has the advantage of being simple and easy to compute, but it also ome drawbacks, as it is generally not reliable and it is not applicable when a number of ground points is available."
31,"first of all, once the two sets are se- d, accuracy estimate is not reliable since it is strictly dependent on the points as cps; if outliers or poor quality points are included in the cps set, accuracy ate is biased."
31,"in addition, when a low number of ground points is available, st all of them are used as gcps and very few cps remain, so that rmse may mputed on a poor (not significant) sample."
31,"in these cases, accuracy assess- with the usual procedure is essentially lost."
31,"in addition, this method displays efficiency, making a poor use of the available information, as a large part of st be collected and used only for validation purpose."
31,2 leave one out cross validation order to overcome the drawbacks of hov a possible alternative procedure to rm accuracy assessments of orthorectified image is the leave-one-out cross- ation (loocv) method.
31,"the loocv is a statistical estimation technique ntly applied in different fields such as machine learning (elisseeff and pontil ), bioinformatics (simon et al. 2003) and generally in any other field requir- n evaluation of the performance of a learning algorithm (e.g. in geostatistics). a special case of the k-fold cross-validation method (stone 1974, geisser ), which involves the partitioning of the original data set in k subsets of equal approximately)."
31,"the model is trained k times, using each subset in turn as the et, with the remaining subsets being the training set."
31,the overall accuracy can tained averaging the accuracy values computed on each subset.
31,"the loocv -fold cross-validation computed with k=n, where n is the size of the original et."
31,"each test set is therefore of size 1, which implies that the model is trained es."
31,"therefore, the alternative proposal consists in applying the loocv as an ive accuracy evaluation method for image orientation, being particularly use- hen a low number of ground points is available. is method applied involves the iterative application of the orientation model, all the known ground points as gcps except one, different in each iteration, as a check point."
31,"in every iteration, the residuals between image derived co- ates and the cp coordinates (prediction error of the model on cp coordi- ) are calculated."
31,"the overall spatial accuracy achievable from the oriented e may be estimated by calculating the usual rmse or, better, a robust accu- ndex like the median absolute deviation (mad) of the prediction errors on e iterations."
32,"able and robust method, not dependent on a particular set of cps and on out- and it allows us to use each known ground point both as a gcp and as a cp, mizing all the available ground information."
32,"obviously, this is of particular ancy when the ground point number is kept as low as possible due to budget r logistic constraints."
32,loocv may obviously apply to both with a rigorous with a rpc-based (with possible zero or first order correction) orientation l. me experiments were carried out to assess how well loocv derivable accu- indices (mad and rmse) are able to represent the overall accuracy and h are their advantages with respect to the hov rmse.
32,"they led to the fol- g main conclusions, pointing out that the loocv method with accuracy ated by mad seems promising and useful for practical cases: e loocv rmse and hov rmse are too sensitive to outliers and “critical” ints (mainly located along the perimeter of the area covered by ground ints), which may display high residuals when they act as cps."
32,"ov rmse displays the risk to be too dependent on the geometric distribution cps, so that the hov derived accuracy is likely to be not representative for e whole image when only a few cps are available. e loocv mad is a robust index able to filter out the effect of the high re- duals; this is of particular relevancy for the “critical” points, which are not presentative of the mean achievable accuracy. nally a simple decreasing exponential function was proposed to represent the acy trend versus the number of gcps."
32,"this model may be conveniently ap- to loocv mad to find the minimum number of gcps for accuracy as- ment when a number of ground points is available: −t y = a ⋅ ebx (4.60) e y is the rmse, x is the number of gcps used to build the model, a and b timated with standard deviation (σa, σb) by ls adjustment. e value of t is calculated iteratively, starting with t = 1 and estimating the coefficients a and b."
32,"if the difference from the asymptotic value at gcp / 2 (that is y (ngcp / 2) − a ), is larger than a chosen threshold (e.g. >1 he value of t is increased by a unit and the estimates of a and b have to be re- uted."
32,this choice to constrain the slope of the function to the asymptotic has been done in order to avoid that possible false oscillations of estimated acy on a few cps can affect the estimation of the a and b parameters.
32,"the as- otic value a±σa enables the determination of the number of gcps (ñgcp) suf- t to achieve the maximum accuracy, that is the x value corresponding to + 2σ a (2σ upper confidence limit) rounded to the nearest upper integer (fig. ."
33,gcp (4.61) ln(a + 2σ a ) − ln a fig.
33,4.15 example of rmse cp vs. n° gcp fit application of the orientation models is section presents some results obtained using the previously described ori- on models.
33,"the orientation models are implemented in a scientific software ar - software per immagini satellitari ad alta risoluzione) developed at the (dipartimento di idraulica trasporti e strade), area di geodesia e geo- a, sapienza università di roma."
33,"sisar results are compared with orienta- models implemented in commercial software (orthoengine 10.0 pci geo- a, erdas 9.0, leica geosystems) (crespi et al. 2008a, bianconi et al 2008, pi et al 2008b)."
33,"all images of rome (2 eros-a, 2 quickbird, 1 ikonos, 1 sat-1) cover areas of different dimensions; the gps were surveyed with static t static procedures by a trimble 5700 gps receiver and their coordinates are ated by trimble geomatic office software with respect to available gps anent stations (mose at rome faculty of engineering)."
33,the mean horizontal ertical accuracies of the coordinates are between 10 and 20 cm.
33,"the two au- (sicily) scenes are a stereopair, with ground points (gps) positioned in the apping area."
33,the salerno image includes three different quickbird standard at images coming from the same orbital segment; the particularity of this im- the latitude extension (around 48 km). e ground points for the augusta and salerno images were surveyed by geo- quality gps in rtk mode; the mean horizontal and vertical coordinate accu- s are between 5 and 10 cm.
33,the point distribution on bagnoli stereopair is not geneous due to the sea in the south-west area.
33,the ground points of bagnoli acquired by gps surveys using topcon legacy receivers in post processing dure with respect to quite far permanent stations.
33,the mean horizontal and
34,"s for the castelgandolfo area were collected in rtk mode, the mean horizon- d vertical coordinate accuracies are around 15 cm."
34,"the ground coordinates l points are expressed in the wgs84 system, while the orthometric heights obtained applying geoid undulations from the italgeo95 public model. r each image and for each software the orientation was carried out several , varying the number of gcps, and the related accuracies, represented by the e computed over check point residuals (rmse cp), were computed and ana- ."
34,the rmses were computed both for the north and east residual compo- separately. e available images for the experimentation have been acquired by several rs.
34,their features are summarized in table 4.21.
34,table 4.2 properties of the used data sets off-nadir scene coverage available ensor area gsd [m] angle (°) (km x km) gps start end rome (r1) 1.80 9.1 9.4 13x10 49 ros a rome (r2) 2.60 31.0 40.1 17x12 49 rome (level 1a) 0.61 3.0 17x17 49 rome (level 1b) 0.60 2.2 17x17 24 ckbird augusta (*p001) 0.77 29.2 21x20 39 augusta (*p002) 0.75 28.2 20x19 39 salerno “joint” 0.67 20.0 48x19 57 bagnoli-1 1.00 22.98 13x9 25 konos bagnoli-2 1.00 24.27 13x9 25 rome 1.00 18.7 11x10 27 rome banda 2.5 4.97 7.5x30 43 rome bandf 2.5 26.09 7.5x30 43 castelgandolfo tosat-1 2.5 12.35 30x30 25 banda castelgandolfo 2.5 28.20 30x30 25 bandf ros a rome (r1): ita1-e1038452; os a rome (r2): ita1-e1090453; ckbird salerno “joint” is obtained to stitch three quickbird images in order to have a single “strip” image: ckbird salerno (*p001): 05jul17100900-p1bs-005520834030_01_p001; ckbird salerno (*p002): 05jul17100903-p1bs-005520834030_01_p002; ckbird salerno (*p003): 05jul17100906-p1bs-005520834030_01_p003; ckbird augusta (*p001): 04jan06093201-p1bs-000000130187_01_p001; ckbird augusta (*p002): 04jan06093307-p1bs-000000130187_01_p002; ckbird rome (level 1a): 02jun03100558-p1bs-000000032060_01_p001; ckbird rome (level 1b):05apr28101432-p2as-005746807010_01_p001 nos rome: po_15194; nos bagnoli-1: po_918_pan_0000010001; nos bagnoli-2: po_918_pan_0010000001;
35,n image eros a of rome (fig.
35,4.16) was oriented with the two rigorous ls implemented in sisar and in orthoengine.
35,results in terms of rmse on are compared.
35,"rmse trend are globally similar for both software and its is comparable with the gsd, except for the north component. .2 rigorous model for single image (level 1b) example for the level 1b imagery, one image was selected, acquired respec- by ikonos (fig."
35,4.17) satellites.
35,image represents the area of city of rome. mage has been oriented with rigorous models implemented in sisar and in oengine.
35,also in this case the rmse trend is similar for both software and acy is around the gsd value.
35,4.16 image accuracy vs.
35,gcp number for eros a (ita1-e1090724) fig.
35,4.17 image accuracy vs.
35,gcp number for ikonos image of rome
36,ne example of stereopair orientations using rigorous models is presented.
36,it erns along-track stereopair acquired by cartosat-1 satellite (fig.
36,4.18).
36,"notice cartosat-1 is a satellite dedicated expressly to stereo viewing, having two -line sensor cameras, looking respectively in forward direction with a nadir of 26° and in aft direction with a nadir angle of 5°."
36,"for the cartosat-1 stere- rmse cp trend in all components is similar, except for the east component e sisar results are less than 2.0 m, while orthoengine ones are slightly e."
36,4.18 image accuracy vs.
36,"gcp number for cartosat-1 stereopair of rome .4 usage and generation rpc for single image e next example is dedicated to the application of rpc model, supplied by the r managing companies, to a quickbird image of rome."
36,"model was tested three software, in fact the sisar results are compared with the orthoengine rdas ones (fig."
36,4.19).
36,4.19 image accuracy vs.
36,gcp number for quickbird image of rome
37,kbird salerno “joint” image.
37,"these example is very interesting, since rpcs e whole strip are not available by the sensor managing companies, but they de rpcs only for the three separated images. this case the results obtained from rpc generated in sisar are compared the results of rigorous model implemented in orthoengine (fig."
37,4.20).
37,"the er differences between the two model are showed in j direction, the rmse end with rpc model is more consistent than rmse cp trend obtained with ous model."
37,4.20 image accuracy vs.
37,"gcp number for quickbird salerno “joint” .5 stereo model via rpc nally, an example of stereopair orientation via rpc are presented."
37,the stere- used is acquired by cartosat-1 satellite on the area of castelgandolfo.
37,re- of sisar software are compared with the erdas ones (fig.
37,4.21).
37,4.21 image accuracy vs.
37,gcp number for cartosat-1 stereopair of castelgandolfo
38,"this paragraph, results on satellite images, described in the data set table 4.2), are presented."
38,single images and stereopairs have been oriented with ous and rpc model.
38,"the next tables (table 4.3, 4.4, 4.5) list the accuracy for rientation tests performed with a number of gcps, evaluated with the (4.61), d to achieve the maximum accuracy."
38,table 4.3 results of rigorous model applied to single images rigorous model single image rmse cp sensor area sisar orthoengine n° gcp e[m] n[m] n° gcp e[m] n[m] salerno “joint” 17 0.52 0.84 21 0.72 0.65 quickbird rome (level 1b) 10 0.54 0.30 10 0.49 0.38 ikonos rome 10 0.87 0.67 10 0.97 0.74 eros a rome (r2) 17 4.11 5.45 17 4.75 7.54 table 4.4 results of rigorous model and rpc model applied to stereopairs rigorous model for stereo images rmse cp ensor area sisar orthoengine n° gcp e[m] n[m] up[m] n° gcp e[m] n[m] up[m] os a rome 17 2.55 2.75 5.85 21 3.17 4.40 6.97 kbird augusta 13 0.58 0.84 1.02 21 0.78 1.07 1.33 tosat rome 15 1.58 1.60 2.27 15 2.07 1.63 2.13 onos bagnoli 11 1.93 1.35 1.95 13 0.90 1.55 1.95 rpc model for stereo images rmse cp ensor area sisar erdas n° gcp e[m] n[m] up[m] n° gcp e[m] n[m] up[m] osat-1 castelgandolfo 12 1.53 1.19 1.29 12 1.53 1.21 1.29 ble 4.5 comparison of results of rpc generated with sisar and rigorous model ones rpc generation rmse cp sensor area sisar rpc orthoengine rigorous model n° gcp i [pix] j [pix] n° gcp i [pix] j [pix] eros a rome 13 2.01 2.75 13 1.85 3.17 quickbird salerno “joint” 13 0.91 1.67 17 0.78 1.45
39,"the following, the results of accuracy assessment by loocv method are nted."
39,the results are related to the quickbird image of augusta.
39,to test the osed method a new routine performing loocv into the software sisar implemented to perform the rigorous orientation of hrsi.
39,"moreover, the im- was also oriented by orthoengine, manually performing loocv since only is possible with this software."
39,"no large residuals are evidenced in this case he loocv accuracies (rmses and mads) have essentially the same order agnitude of hov rmse (table 4.6), but again mads are slightly lower than rmses and they are significantly closer to hov rmses than loocv es. ble 4.6 comparison between models and accuracy indices (in pixels) for augusta image accuracy index sisar orthoengine loocv north east module north east module rmse 1.52 1.45 2.09 1.83 1.56 2.40 mad 1.01 1.17 1.77 1.19 0.96 1.68 abs max 3.36 3.64 3.78 3.62 3.54 4.59 hov north east module north east module rmse 1.16 1.38 1.80 1.32 1.33 1.87 summary gh resolution satellite imagery became available to civilian users in 1999 the launch of ikonos, the first civilian satellite offering a spatial resolution of since then, other high resolution satellites have been launched, among which ros-a (1.8 m), quickbird (0.61 m), orbview-3 (1 m), eros-b (0.7 m), dview-1 (0.5 m) and geoeye-1 (0.41 m), with many others being planned to h in the near future. gh resolution satellite imagery is now available in different formats and ssing levels at an affordable price so that they already represent a possible al- ive to aerial imagery for cartographic applications and orthophoto produc- especially for areas where the organization of photogrammetric surveying be critical."
39,"moreover, an increasing demand for terrain modeling exists so lmost all the satellites have along-track stereo acquisition capability."
39,"many satellites dedicated to stereo viewing, for example cartosat-1 (2.5 m), have launched."
39,"this enables the generation of digital elevation models, digital sur- models, and 3d features, e.g. city models. e geomatic utilizations of satellite imagery for cartographic applications and n modeling requires a high level geometric correction through image orienta- some fundamental problems related to sensor models and their parameters ation, both for single images and stereopairs, were addressed and some real cations were discussed."
40,"eneralized sensor models for the orientation of basic images (level 1a) and e image projected onto a specific object surface (usually an expanded ellip- derived from the wgs84, level 1b)."
40,"as for the rigorous models, a thorough tigation on the fundamentals of their functional model was developed and the of parameter estimability was concerned."
40,a solution was proposed based on and qr decompositions.
40,"rpc models were discussed not only with respect ssible refinements by zero and first order transformations, but also (and y) with respect to the rpcs generation, based on previously established rig- model."
40,"thanks to svd and qr decompositions, it was shown that many are not estimable parameters, therefore, they are not necessary to obtain the chievable accuracy level. al applications demonstrated that rigorous and rpc models both for level nd level 1b imagery can provide an orientation accuracy at the level of 1-1.5 s in the horizontal components, and of 1-2 pixels in the height for stereopairs better with cartosat-1 and slightly worse with eros-a). oreover, hov and loocv methods for accuracy assessment were discussed ompared, showing that the drawbacks of the usually adopted hov can be ome by loocv."
40,"loocv is reliable and robust, not dependent on a particu- t of cps and on outliers, which allows the use of each known ground point as a gcp and as a cp, maximizing all the available ground information."
40,"ob- ly, this is of particular relevancy when the number of ground points is kept as s possible due to budget and/or logistic constraints."
40,"loocv may obviously to both rigorous and rpc-based (with possible zero or first order correction) tation models. nally, a simple but effective method to represent the accuracy trend versus umber of gcps was proposed."
40,this model may conveniently be applied to cv to find the minimum number of gcps for accuracy assessment when a er of ground points are available. nowledgments e authors would like to thank very much: aria a.
40,"brovelli, armin gruen, karsten jacobsen and eugenio realini for fruitful discussions; e leica geosystems company who supplied the erdas software; valerio selli (informatica per il territorio s.r.l., rome, italy), fabrizio filiberti (sys- italia, rome, italy) and fabio volpe (eurimage s.p.a., rome, italy), who y supplied the eros-a1, ikonos and quickbird imagery, respectively; ura de vendictis, lucia luzietti and augusto mazzoni who carried out some ground points global navigation satellite system (gnss) surveys."
41,ha (1992) geometric and radiometric analysis of a ccd-camera based photogrammetric se-range system.
41,"phd thesis, institut fur geodasie und photogrammetry, nr."
41,"51, eth, zu- h, may 1992 oni m, crespi m, fratarcangeli f, giannone f, pieralice f (2008) a new strategy for ra- nal polynomial coefficients generation."
41,"proceeding earsel joint workshop remote nsing, new challenges of high resolution, bochum (germany) march 5-7 2008 li m.a, crespi m, fratarcangeli f, giannone f, realini e (2008) accuracy assessment of h resolution satellite imagery orientation by leave-one-out method, isprs journal of pho- rammetry and remote sensing, vol.63 issue 4 pags."
41,427-440 dc (1971) close-range camera calibration.
41,photogrammetric engineering.
41,"vol.37, no."
41,"8, 855-866 m, fratarcangeli f, giannone f, pieralice f (2008a) orientation of quickbird, ikonos and os a stereopairs by an original rigorous model international calibration and orientation orkshop."
41,"proceeding of eurocow 2008, castelldefels (spain) january 30-february 1 2008 m, fratarcangeli f, giannone f, jacobsen k, pieralice f (2008b) orientation of cartosat- stereo imagery."
41,"proceeding of earsel joint workshop remote sensing, new challenges high resolution, bochum (germany) march 5-7 2008 eff a, pontil m (2002) leave-one-out error and stability of learning algorithms with appli- ions."
41,"advances in learning theory: methods, models and applications:111-130."
41,"nato vanced study institute on learning theory and practice c s and hanley h b (2003) bias compensation in rational functions for ikonos satellite agery photogrammetric engineering and remote sensing, vol. 69(1), pp. 53-57 r s (1975) the predictive sample reuse method with applications."
41,"journal of the american tistical association, vol."
41,"70, no. 350, pp.320-328 one f (2006) a rigorous model for high resolution satellite imagery orientation."
41,phd esis of the sapienza university of rome.
41,supervisors: m.
41,crespi.
41,"available: p://w3.uniroma1.it/geodgeom/personale.htm#dottoriricerca g, van loan c f (1993) matrix computation."
41,"the johns hopkins university press, bal- more and london y h b, fraser c s (2004) sensor orientation for high-resolution satellite imagery: further ights into bias-compensated rpc, available: p://www.isprs.org/istanbul2004/comm1/papers/5.pdf ann wellenhof b, lichtenegger h, wasle e (2008) gnss global navigation satellite sys- m, spinger-verlag."
41,isbn: 978-3-211-73012-6 en k (1998) geometric calibration of space remote sensing cameras for efficient process- .
41,"iaprs, vol."
41,"32, part 1, pp."
41,33-43 wm (1966) theory of satellite geodesy.
41,"blaisedell publishing company nbruck o, gill e (2001) satellite orbits."
41,"springer, berlin aier a (1998) solving ill-conditioned and singular linear systems: a tutorial on regulariza- n siam review, issue 3, vol. 40 pp."
41,636-666 (2000) the compendium of controlled extensions (ce) for the national imagery trans- ssion format (version 2.1) nitfs technical board linger pd (1999) atmospheric refraction effects in earth remote sensing.
41,"isprs journal of otogrammetry & remote sensing vol. 54, pp. 360–373 ce f (2007) orthorectification of ikonos high resolution satellite imagery: definition, plementation and accuracy assessment of an original orientation model."
41,degree thesis of sapienza university of rome.
41,supervisors: m.
41,crespi.
41,not published (2005) modelling of spaceborne linear array sensors.
41,"diss., technische wissenschaften h zurich, nr."
41,"15894, igp mitteilung"
42,"(1), 14-18."
42,oxford university press m (1974) cross-validatory choice and assessment of statistical predictions (with discus- n).
42,"journal of the royal statistical society b, no. 36, pp.111-147 g, borre k (1997) linear algebra, geodesy and gps."
42,"wellesley-cambridge press, ellesley v, hu y (2001a) the rational function model-a tool for processing high resolution im- ery earth observation magazine, vol. 10 (1), pp."
42,"13-16 v, hu y (2001b) a comprehensive study of the rational function model for photogram- tric processing photogrammefric engineering & remote sensing, vol. 67(12), pp."
42,"1347- 57 v, hu y (2001c) use of the rational function model for image rectification canadian jour- of remote sensing, vol. 27(6), pp."
42,593-602 v and hu y (2002) 3d reconstruction methods based on the rational function model.
42,"pho- rammetric engineering &remote sensing, vol. 68(7), pp.705-714 sen p.j.g, kleusberg a (1998) gps for geodesy, springer-verlag."
42,"isbn: 3-540-63661-7 t, chénier r, carbonneau y (2000) 3d models for high resolution images: examples with ickbird, ikonos and eros in proceedings of isprs commission iv symposium, joint in- national symposium on geospatial theory, processing and applications, ottawa, pp. 547- 1 n t (1990) precision rectification of spot imagery."
42,"photogrammetric engineering and mote sensing vol.56, n. 2, pp."
42,247–253
