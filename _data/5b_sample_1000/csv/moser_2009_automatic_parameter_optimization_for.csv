page,p
1,"ieee transactions on geoscience and remote sensing, vol."
1,"47, no."
1,"3, march 2009 909 automatic parameter optimization for support vector regression for land and sea surface temperature estimation from remote sensing data gabriele moser, member, ieee, and sebastiano b."
1,"serpico, senior member, ieee abstractâ€”land surface temperature (lst) and sea surface and surface, vegetation and soil moisture, numerical weather temperature (sst) are important quantities for many environ- prediction, climatic variability, and global ocean circulation [1]. mental models."
1,remote sensing is a source of information for their many algorithms have been devised to obtain lst and sst estimation on both regional and global scales.
1,"many algorithms have been devised to estimate lst and sst from satellite data, from space radiometry [2]â€“[5]."
1,"most of them require a priori most of which require a priori information about the surface and information about the state of the atmosphere (e.g., temperature the atmosphere."
1,"a recently proposed approach involves the use of and water vapor profiles) and about the surface (e.g., emis- support vector machines (svms)."
1,"based on satellite data and cor- sivity), without which accurate surface temperature estimation responding in situ measurements, they generate an approximation becomes more difficult [6]â€“[12]."
1,"by itself, the estimation of of the relation between them, which can subsequently be used to estimate unknown surface temperatures from additional satellite these surface and atmospheric parameters is often a difficult data."
1,such a strategy requires the user to set several internal task to be addressed prior to or jointly with surface temperature parameters.
1,"in this paper, a method is proposed for automatically estimation [3], [8], [12]."
1,"traditional methods, such as the well- setting these parameters to quasi-optimal values in the sense of known split-window techniques [1], are typically calibrated minimum estimation errors."
1,"this is achieved by minimizing a (once and for all) for given sensors (e.g., noaaâ€“avhrr, functional correlated to regression errors (i.e., the â€œspan-boundâ€ upper bound on the leave-one-out (loo) error) which can be modis, meteosat second generation (msg)â€“seviri) by computed by using only the training set, without need for a fur- least squares fitting."
1,these regressions are applied according to ther validation set.
1,"in order to minimize this functional, powellâ€™s predefined sets of values of surface and atmospheric data and to algorithm is adopted, since it is applicable also to nondifferentiable the resulting simulated top-of-atmosphere brightness temper- functions."
1,"experimental results yielded by the proposed method atures [5], [12], [13]."
1,"they can then be applied to a satellite are similar in accuracy to those achieved by cross-validation and by a grid search for the parameter configuration which yields the image in an unsupervised way, i.e., with no need for training best test-set accuracy."
1,"however, the proposed method gives a dra- in situ temperature data, even though the aforementioned sur- matic reduction in the computational time required, particularly face and atmospheric data for the related geographical area are when many training samples are available. still required."
1,"thorough reviews of the lst and sst estimation index termsâ€”generalization error bounds, land surface tem- problems from satellite data can be found in [1], [13], and [14]. perature (lst), powellâ€™s method, sea surface temperature (sst), a different approach to lst estimation has recently been supervised regression, support vector machines (svms). proposed in [15] based on pattern recognition, in particular on support vector machines (svms)."
1,svms represent a family of i.
1,"i ntroduction powerful supervised learning techniques, and their application to the temperature estimation problem allows one to compute s atellite remote sensing systems provide a repetitive and consistent view of the earthâ€™s surface at different observation scales."
1,measurements made by onboard sensors are a nonparametric approximation of the relationship between satellite data and matching in situ measurements (adopted for training purposes).
1,this supervised regression strategy can be a feasible way to derive earth-surface parameters from surface- theoretically proven to exhibit very good generalization and leaving radiation on both regional and global scales.
1,land robustness properties [16].
1,"it has also been experimentally surface temperature (lst) and sea surface temperature (sst) demonstrated that such a strategy can generate more accurate are important quantities for many environmental models, such estimates, as compared with the aforementioned standard tech- as the energy and mass exchange between the atmosphere niques, even though at the expense of increased complexity and computational time [15]."
1,"in the context of remote sensing, manuscript received september 25, 2007; revised february 21, 2008 and svm regression has recently been used also for biophysical june 24, 2008."
1,"first published february 3, 2009; current version published parameter estimation from multispectral images of sea water february 19, 2009."
1,"this work was supported by the italian department of civil [17]â€“[20], for evapotranspiration evaluation from meteorologi- protection under the proscenio 2005â€“2008 program."
1,"the authors are with the department of biophysical and electronic en- cal, flux, and modis data [21], and for leaf-area-index estima- gineering (dibe), university of genoa, 16145 genova, italy, and also with tion from radiometric data [22]. the interuniversity research center in environmental monitoring (cima), unlike traditional methods, the svm-based approach is 17100 savona, italy (e-mail: gabriele.moser@unige.it; sebastiano.serpico@ unige.it). supervised and requires in situ temperature measurements to digital object identifier 10.1109/tgrs.2008.2005993 be used for training purposes, but it does not involve an 0196-2892/$25.00 Â© 2009 ieee authorized licensed use limited to: univ of calif santa barbara."
1,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
1,restrictions apply.
2,"910 ieee transactions on geoscience and remote sensing, vol."
2,"47, no."
2,"3, march 2009 explicit characterization of surface and/or atmospheric param- is extended to support vector regression: two parameter opti- eters."
2,"from this perspective, such an approach is comple- mization methods are developed by generalizing to regression mentary with respect to the traditional methods."
2,radiometric the aforementioned radius-margin and span bounds and by and/or subsurface ground temperature measurements are reg- combining them with quasi-newton procedures while focusing ularly acquired by several networks of micrometeorological on svm with quadratic penalty on the slack variables.
2,"note stations (e.g., the well-known â€œoklahoma mesonetâ€ network in that, in this approach, the radius-margin bound for regression oklahoma (usa) or similar networks installed in several river exhibits quite a low correlation with actual regression errors basins for flood prevention and environmental monitoring)."
2,sea on test samples and that the span bound for regression is a temperature measurements are acquired on a regular basis by nondifferentiable function of the unknown parameters.
2,"to over- suitably equipped moored and drifting buoys. come the latter issue, a differentiable modified bound is used the svm-based strategy in [15] involves tuning several in [35], even though this requires the introduction of a further internal parameters, whose values influence the svm-generated smoothing parameter to be manually set."
2,"the rademacher approximation function and must be preliminarily set by the complexity bound holds in the case of regression as well [30], user, typically via â€œtrial-and-errorâ€ grid searches for the lowest [36], and a closed-form analytical formulation of the bound regression error (e.g., cross-validation (cv) or loo error)."
2,"this is available for a kernel-based functional approximator (such process is often time consuming, due to the need to repeat as the ones given by svms), even though it does not have a the svm training for each node in the grid, and it is also bias term. sensitive to the (usually empirical) choice of the related ranges in this paper, a method is proposed that automatically sets and discretization steps of the parameters."
2,"in particular, the time the parameters required by svm regression in order to mini- requirement for grid searches can become critical when large mize estimation errors."
2,"the method is applied in the context in situ data sets are available for training purposes, which may of the svm approach to lst estimation; this approach is occur, for instance, when in situ stations continuously provide also extended to the sst case and can be generalized to temperature measurements over a long time."
2,this calls for the the estimation of further bio-/geophysical parameters as well. availability of fast and automatic parameter-setting procedures.
2,"the proposed automatic parameter optimization method lies in in this paper, we focus on the problem of the automatic minimizing the span-bound functional, which is known to be optimization of the input parameters characterizing an svm re- strongly correlated with estimation errors and can be computed gression method."
2,"in the literature, this problem has been mainly by using only the training set [35]."
2,"unlike [35], the svm with addressed in the context of support vector classification and has linear penalty on the slack variables is adopted, since it usually been expressed as the numerical minimization of upper bounds ensures better sparsity of the resulting functional approximator, on the generalization error of the classifier [23], [24]."
2,"in [23], while limiting possible risks of overfitting and reducing the time several of such bounds (e.g., the â€œradius-margin boundâ€ and the required to generate maps of lst and sst estimates, when â€œspan boundâ€) are introduced or revised while focusing on the compared to using a quadratic penalty [16]."
2,powellâ€™s method family of support vector classifiers with quadratic penalty on is the algorithm chosen to address the minimization problem the slack variables [16].
2,"gradientlike minimization procedures because it is applicable to nondifferentiable functions as well are also developed for such bounds, provided that they are [37], such as the considered span bound."
2,this prevents the need differentiable.
2,"this approach is extended in [24] to support to introduce regularized versions of the functional, which also vector classifiers with linear penalty on the slack variables [16] involve further parameters to be manually set. by combining a heuristic generalization of the radius-margin the main novelty of this paper lies in the combination of the bound and a quasi-newton minimization algorithm."
2,"in [25], span-bound functional for svm regression with linear penalty several error bounds (i.e., the â€œÎ¾Î± boundâ€ [26], the â€œgeneralized on the slack variables and powellâ€™s algorithm, in order to approximate cvâ€ [27], the â€œapproximate span boundâ€ [28], the obtain complete automation of the estimation of lst and sst â€œvapnikâ€“chervonenkis boundâ€ [29], and the aforementioned from satellite data."
2,"here, we do not focus on the applicative radius-margin bound) are revised and experimentally compared aspects related to lst and sst retrieval from satellite data, in the contexts of support vector classification with both linear but we rather concentrate on the methodological problem of and quadratic penalties on the slack variables."
2,"in [30], quan- automatic parameter optimization for support vector regression. titative bounds on the error probability of general families of accordingly, the experimental results regarding lst estimation discriminant functions are formulated in terms of classifica- from avhrr and msg images and sst estimation from tion errors on the training samples and of an analytical mea- avhrr data are compared with those obtained by a frequently sure of the complexity of the classifier (i.e., the rademacher applied approach to parameter setting, i.e., the grid search for complexity). the parameter configuration yielding the smallest cv or test-set as far as support vector regression is concerned, semiheuris- (hold-out) error."
2,more application-oriented comparisons with tic approaches to parameter setting have been proposed in classical lst and sst estimation algorithms can be found in [31] and [32] by relating the parameters with the noise and [15] and [38]. input data statistics.
2,bayesian methods for parameter estimation this paper is organized as follows.
2,"the proposed approach have been proposed in [33] and [34], even though they focus is described in section ii, after briefly revising the main ideas on case-specific svm architectures (without the bias term in and notations of support vector regression."
2,experimental results [34] and with an ad hoc loss function in [33]).
2,"in [35], the are presented in section iii, and conclusions are drawn in approach based on gradientlike minimization of error bounds section iv."
2,authorized licensed use limited to: univ of calif santa barbara.
2,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
2,restrictions apply.
3,moser and serpico: parameter optimization for regression for land and sst estimation 911 ii.
3,m ethodology expansion in (1) is obtained by solving the following quadratic programming (qp) problem [16]: a.
3,"support vector regression for lst and sst estimation  1   postulating the existence of a relation between the surface min 2Î² q(Î³)Î² âˆ’ y  Î² + ÎµÎ²1 Î²âˆˆrn (2) temperature of an observed geographical area and the spec- tral radiance measured by a remote sensor over this area, 1 Î² = 0, Î²âˆ â‰¤ c an evaluation of the surface temperature would require the inversion of this relation: from a learning-oriented perspective, where c and Îµ are further svm parameters, q(Î³) is the n Ã— n this suggests using regression methods."
3,"accordingly, a super- matrix whose (h, k)-entry is given by qhk (Î³) = k(xh , xk |Î³) vised estimation scheme based on svms has been adopted and (h, k = 1, 2, . . . , n ), y = [y1 , y2 , . . . , yn ] is the vector of the applied to passive sensor data in [15]."
3,"n in situ measurements, and 1 is an n -dimensional vector the svm approach aims at expressing a learning task with unitary components."
3,"an important property of svms is (i.e., classification, regression, or probability density estimation that the resulting qp solution is globally optimal, while other [39]) by explicitly optimizing a measure of the optimization supervised learning techniques (e.g., neural networks) only capability of the learning machine."
3,"given a training set for ensure a local minimum of the approximation error to be found which the corresponding in situ measurements are known, [16]."
3,"numerical techniques to efficiently solve this qp problem the svm generates an approximation of the relation between are available in the literature [40], [41]. satellite data acquired over a certain area and the corre- the parameter c(c > 0) tunes the tradeoff between the sponding lst. generalization capability of the functional approximator and specifically, denoting x as the n-dimensional feature vector the accuracy of the fitting on the training set: a large value extracted from the acquired sensor data for a given pixel, y as of c allows a high regression accuracy on the training set to the corresponding earth-surface physical quantity to be esti- be achieved, but may encourage overfitting, thus causing a high mated (either lst or sst), and f : rn â†’ r as the unknown sensitivity to noise and to possible errors on the training data. function relating the features with this physical quantity (i.e., a small value of c aims at optimizing the smoothness and y = f (x), up to possible noise), the svm approach allows an generalization capability of the approximator, but may poorly estimate fË† by minimizing an upper bound on the probability fit the training set, thus causing a reduced accuracy of the ap- that the estimation error may be above a given threshold [16]. proximation of the estimated function."
3,"the parameter Îµ(Îµ > 0) given a set {(x1 , y1 ), (x2 , y2 ), . . . , (xn , yn )} of n training represents the largest (absolute) error that is considered accept- samples (where xh is the feature vector for the hth training able and is not penalized at all in the svm training process sample and yh is the corresponding in situ measurement; h = [16]."
3,"the vector of all the input parameters of the svm regres- 1, 2, . . . , n ), the resulting approximation turns out to be ex- sion method can be defined as Î¸ = (ln c, ln Îµ, Î³) âˆˆ rm , where pressed as a linear combination of appropriate kernel functions m = r + 2 is the number of parameters, and the logarithm is centered on a subset of training samples [16] applied to c and Îµ in order to let Î¸ take on values in the whole space rm , with no explicit positivity constraint."
3,"given a value  for Î¸, the training of the svm consists in the solution of the fË†(x) = Î²hâˆ— k(xh , x|Î³) + bâˆ— (1) qp problem in (2): we stress the dependence on Î¸ by denoting hâˆˆs as Î² âˆ— (Î¸) and s(Î¸) the resulting weight vector of the linear where Î²1âˆ— , Î²2âˆ— , . . . , Î²n âˆ— are the weight coefficients of the linear combination and the related index set of the support vectors, combination, k(Â·, Â·|Î³) is a kernel function parameterized, in respectively."
3,"a more detailed discussion of svm regression can general, by a vector Î³ of r real-valued parameters (Î³ âˆˆ rr ), be found in [16]. bâˆ— is a bias term, and s = {h : Î²hâˆ— = 0} [16]."
3,"if h âˆˆ s, i.e., Î²hâˆ— = 0, the training sample xh is named â€œsupport vector.â€"
3,proposed parameter optimization method necessary and sufficient conditions (the so-called â€œmercerâ€™s conditionsâ€) are known for a given function of two vectors to be the key idea of the proposed parameter optimization tech- a kernel [16].
3,"for instance, gaussian and symmetric hyperbolic nique is to search for a parameter vector that minimizes an tangent functions are popular kernels."
3,we assume that the vec- upper bound on the regression error.
3,"specifically, one can prove tor Î³ of the internal parameters of the kernel is defined such that that, under mild assumptions, the average â€œlooâ€ regression it can take on values in the whole space rr ."
3,"the vector1 Î² âˆ— = error can be upper bounded by the following functional, named âˆ—  [Î²1âˆ— , Î²2âˆ— , . . . , Î²n ] of the coefficients characterizing the kernel â€œspan boundâ€ [35]: 1  j(Î¸) = |Î²hâˆ— (Î¸)| s2h (Î¸) n hâˆˆs(Î¸)  âˆ— y Î² (Î¸) âˆ’ Îµ Î² âˆ— (Î¸)1 âˆ’ Î² âˆ— (Î¸) q(Î³)Î² âˆ— (Î¸) 1 given that p â‰¥ 1 and v âˆˆ rm , we denote by v and v âˆ the pth- + +Îµ (3) p cn order minkowski norm (i.e., vp = (|v1 |p + |v2 |p + Â· Â· Â· + |vm |p )1/p ), and the tchebitchev norm (i.e., vâˆ = max{|v1 |, |v2 |, . . . , |vm |}) of v, respec- tively."
3,"all vectors in this paper are assumed to be column vectors, and the where sh (Î¸), named the â€œspanâ€ of the support vector xh , superscript â€œâ€ denotes the matrix transpose operator. is a real coefficient computed by solving the following qp authorized licensed use limited to: univ of calif santa barbara."
3,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
3,restrictions apply.
4,"912 ieee transactions on geoscience and remote sensing, vol."
4,"47, no."
4,"3, march 2009 problem (h âˆˆ s(Î¸)): in the direction ui,t , i.e., compute the scalar â§ â¨   Ïi,t = arg min j(Î¸Ì„iâˆ’1,t + Ïui,t ) (5) s2h (Î¸) = min Î»i Î»j qij (Î³) âˆ’ 2 Î»i qih (Î³) Ïâˆˆr â© i,jâˆˆu(Î¸) iâˆˆu(Î¸) â« and then move to the resulting minimum point Î¸Ì„i,t =  â¬ Î¸Ì„iâˆ’1,t + Ïi,t ui,t (i = 1, 2, . . . , m)."
4,"+ qhh (Î³) Î» âˆˆ rn , Î»i = 1 (4) 3) update the parameter vector as the last point reached in â­ iâˆˆu(Î¸) the parameter space by the sequence of m line searches performed in step 2), i.e., set Î¸t+1 = Î¸Ì„m,t . and u(Î¸) = {h âˆˆ s(Î¸) : |Î²hâˆ— (Î¸)| < c} = {h : 0 < |Î²hâˆ— (Î¸)| < 4) update the search directions by dropping the first direc- c} identifies a subset of the training set, whose samples (i.e., tion u1,t and introducing a new direction (Î¸t+1 âˆ’ Î¸t ), i.e., xh such that h âˆˆ u(Î¸)) are named â€œunbounded support vectorsâ€ set ui,t+1 = ui+1,t for i = 1, 2, . . . , m âˆ’ 1 and um,t+1 = or â€œfree support vectorsâ€. Î¸t+1 âˆ’ Î¸t ."
4,"given the parameter vector Î¸, the corresponding value j(Î¸) these processing steps are iterated until the relative decrease of the span bound can be analytically computed by solving first in the span-bound functional between successive iterations goes the qp problem in (2), which yields the coefficients Î²hâˆ— (Î¸)(h = below a given threshold, which is very close to the machine 1, 2, . . . , n ) and identifies support vectors and unbounded sup- precision [37]."
4,"the method is analytically proved to quadrat- port vectors, and then the qp problem in (4) for each support ically converge, under mild assumptions, at least to a local vector xh (h âˆˆ s(Î¸)). minimum [37], [42]."
4,"a drawback is that the pseudoconjugate the proposed method aims at searching a parameter vector directions may become linearly dependent during the iterations, Î¸âˆ— âˆˆ rm that minimizes j(Î¸)."
4,"even though the span bound thus implicitly restricting the search space to a lower dimen- can be computed by dealing only with the training samples, sional subspace [43]."
4,"a simple strategy to solve this problem it is known to be a very tight bound, strongly correlated with while keeping the quadratic convergence property consists of the regression error on test samples, provided that the test reinitializing the pseudoconjugate directions to the canonical and training samples are drawn from the same probability basis of rm after each cycle of (m + 1) successive iterations distribution [35]."
4,"however, in general, it is a nondifferentiable [37]."
4,"alternate solutions to this problem, either keeping or function of Î¸, so gradient-based algorithms cannot be used to giving up the quadratic convergence property, are discussed in minimize it."
4,methods that only need to evaluate the functional [37] and [43]. to be minimized are required.
4,"in particular, powellâ€™s method is the line search in step 2) is performed numerically using adopted here, which is an iterative unconstrained minimization brentâ€™s method, which is based on the iterative combination technique evaluating only the functional and not requiring its of the â€œinverse parabolic interpolationâ€ and â€œgolden-sectionâ€ possible derivatives."
4,"powellâ€™s method aims at emulating, with- approaches to single-variable function minimization and is out the use of gradient and hessian information, the behavior of applicable to nondifferentiable functions as well [43]."
4,"given the conjugate gradient method (which, by itself, is applicable a single-variable continuous function to be minimized, the to twice continuously differentiable functions) by identifying golden-section method iteratively computes a sequence of a set of m vectors in rm that are close to being conjugate. bracketing triplets3 that converges to a local minimum point of the minimum of the functional is computed by sequentially the function [37]."
4,"the inverse parabolic interpolation method performing, at each iteration, a line search2 in each of such iteratively minimizes a parabolic interpolation of the input â€œpseudoconjugateâ€ directions [42]. (single-variable) function computed according to the evalua- let Î¸t be the parameter vector computed at the tth iteration of tions of the function in three distinct points."
4,"if the function is the proposed method, ui,t be the ith pseudoconjugate direction monomodal, this method is proved to converge to the desired computed at the tth iteration, and Î¸Ì„i,t be the parameter vector local minimum point."
4,"moreover, it typically converges faster computed after the ith sequential line search of the tth iteration than the golden-section approach."
4,"however, if the monomodal- (t = 0, 1, 2, . . . and i = 1, 2, . . . , m). ity assumption fails, it may not converge [37]."
4,"brentâ€™s method the method is initialized with a given parameter vec- is based on the key idea of iteratively exploiting the inverse tor Î¸0 and with the assumption that the initial directions parabolic interpolation approach when close to a monomodal u1,0 , u2,0 , . . . , um,0 are the canonical basis vectors in rm (i.e., valley of the function to be minimized while using the golden- ui,0 has a unitary ith component, while all the other components section technique otherwise."
4,"basically, during each iteration, a are zero; i = 1, 2, . . . , m)."
4,"then, at each tth iteration of the parabolic interpolation step is attempted, and a series of tests is proposed technique, the following operations are performed performed to discriminate if the resulting solution is acceptable (t = 0, 1, 2, . . .)"
4,"[37], [42]. or if a golden-section step is to be applied."
4,"further details about 1) set Î¸Ì„0,t = Î¸t . the resulting numerical procedure, which is not straightforward, 2) for each ith pseudoconjugate direction ui,t , start from the current point Î¸Ì„iâˆ’1,t , and minimize j(Î¸) by a line search 3 we recall that, given a continuous function g : r â†’ r, a â€œbracket- ing tripletâ€ is a triplet (a, b, c) âˆˆ r3 such that a < b < c and g(b) â‰¤ 2 by â€œline search,â€ we mean the search for the minimum of a given function min{g(a), g(c)}."
4,"thanks to the continuity of g, this condition ensures that of m variables along a straight line in the related m-dimensional space. a local minimum point of g exists in (a, c)."
4,authorized licensed use limited to: univ of calif santa barbara.
4,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
4,restrictions apply.
5,moser and serpico: parameter optimization for regression for land and sst estimation 913 can be found in [43] and [37].
5,the proposed â€œpowell span- â€œagenzia regionale per lo sviluppo e lâ€™innovazione nel settore boundâ€ technique will be denoted by psb in the following.
5,agricolo e forestaleâ€ (arsia) network of the italian tuscany region.
5,samples affected by cloud cover were removed from the data set.
5,the samples acquired by 7 out of the 13 available iii.
5,e xperimental r esults stations were used for training purposes; the ones acquired by the other 6 stations were employed for testing.
5,the resulting a.
5,data sets and experimental setup 149 training and 104 test samples were spatially disjoint.
5,"the method was tested on three real data sets, with two the employed features were the brightness temperature of the of them being related to the lst estimation problem and 10.82-Î¼m seviri channel, the difference between the bright- one being related to the sst case."
5,"the satellite data of ness temperatures in the 10.82- and 12-Î¼m channels, and the the first lst data set (named â€œlst-avhrr-mesonetâ€) were ndvi feature."
5,14 avhrr cloud-free images collected around 7:30 a .
5,"for the sst case, a data set (named â€œsstâ€) was constructed (local time) over oklahoma (usa) between march and from the publicly available multiyear multisatellite â€œavhrr september 2004."
5,the related ground observations are in situ pathfinder matchup databaseâ€ of approximately cotemporal measurements of subsurface soil temperatures at 5 cm un- colocated in situ ssts (acquired from both moored and drifting der native vegetation acquired every 15 min by â€œoklahoma buoys) and avhrr images.
5,"details on this database can be mesonet,â€ an automated network of surface micrometeorolog- found in [49]."
5,"samples collected on two days, i.e., january 1 ical stations covering oklahoma (for each image, the ground and 2, 1999, from globally distributed buoys were used for measurements obtained for the nearest quarter of an hour were experiments."
5,"out of the 215 available samples, 109 were ran- considered)."
5,"the resulting data set was randomly split into domly chosen for training purposes, and the remaining 106 414 training samples and 375 testing samples."
5,"note that, while were used for testing."
5,"as in [49] and [50], four features were the available in situ data were subsurface point measurements considered for each sample, i.e., the secant of the satellite taken at 5 cm, the satellite brightness temperatures are related zenith angle, the measured brightness temperatures of avhrr to the overall radiative surface temperature of the area corre- channels 4 and 3b, and the difference between the brightness sponding to each pixel."
5,"in general, these two data typologies temperatures of channels 4 and 5."
5,the channel-3b (midwave may differ from each other.
5,"however, as discussed in [44], infrared) brightness temperature was used for its correlation the difference between the 5-cm subsurface temperature and with nighttime sst [50] and because the samples in these the skin temperature obtained by correcting infrared radiative data set were collected during two whole days, including both temperature measurements for emissivity is very small around daytime and nighttime acquisitions."
5,"in the daytime, channel 3b 7:00â€“8:00 a ."
5,"m . (local time), which is the acquisition time of the is also affected by solar radiance."
5,"thus, from the viewpoint considered avhrr images."
5,"more generally, svm regression of sst estimation, this feature is expected to be more noisy does not attempt to interpolate the training in situ samples, but it in samples collected in the daytime than in the nighttime. computes a functional approximator of the relationship between anyway, this fact will not be critical due to both the high satellite and in situ data."
5,"thanks to the well-known general- correlation coefficient with sst in situ measurements (around ization properties of svms, possible small differences between 89%, irrespective of acquisition time) and the robustness of subsurface and radiative temperatures at the acquisition time svm to noise. are expected not to significantly affect regression accuracy."
5,"for all three data sets, all the features of the training and to apply svm, three features were considered for each sam- test samples and the temperature values were normalized to the ple, namely, the measured brightness temperatures of avhrr interval [0, 1], and svm was applied with a gaussian radial channel 4, the difference between the brightness temperatures basis function kernel, i.e. (u, v âˆˆ rn ) of channels 4 and 5, and the â€œnormalized difference vegeta-  tion indexâ€ (ndvi)."
5,"one of the two brightness temperatures u âˆ’ v2 k(u, v|Ïƒ) = exp âˆ’ and the difference between them were used instead of the 2Ïƒ 2 two brightness temperatures per se because the difference feature is known to be important for temperature estimation which is parameterized by the standard deviation Ïƒ(Ïƒ > 0). purposes, thanks to its correlation with the atmospheric effects this kernel has frequently been employed in remote sensing ap- on sensor radiance [45]."
5,"the choice of these features extracted plications, and the experimental analysis described in [15] con- from avhrr data was suggested by their use in popular firms that it allows accurate lst estimates to be performed."
5,"the physically based split-window techniques proposed for this resulting parameter vector is defined as Î¸ = (ln c, ln Îµ, ln Ïƒ), sensor [46]â€“[48]. so that all three components of Î¸ can range in the whole the second lst data set (named â€œlst-msg-arsiaâ€) is real line. composed of images acquired over italy between 7:00 and 9:00 a ."
5,m . (local time) by the seviri instrument onboard b.
5,"experiment i: correlation between span bound and (msg) between august 12 and september 19, 2005, and re- test-set errors ceived by the station of the interuniversity research center in environmental monitoring (cima) in savona (italy)."
5,the a first experiment was performed in order to prelimi- related in situ data are radiometric ground temperature mea- narily investigate the choice of the span bound as a func- surements acquired by 13 micrometeorological stations of the tional guiding the parameter optimization process.
5,focusing on authorized licensed use limited to: univ of calif santa barbara.
5,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
5,restrictions apply.
6,"914 ieee transactions on geoscience and remote sensing, vol."
6,"47, no."
6,"3, march 2009 fig."
6,"experiment i: plots of (a) the span bound, (b) the radius-margin bound, (c) the rademacher complexity bound, and (d) the loo error (denoted by sb, rmb, rcb, and loo, respectively, and computed on the training set) and of (e) mae and (f) rmse (in [k]), computed on the test set as functions of the parameters c and Îµ (with Ïƒ = 0.25)."
6,"â€œlst-avhrr-mesonet,â€ the span bound, the radius-margin set."
6,"the radius-margin bound is known to be a loose bound bound, the rademacher complexity bound (computed accord- on the loo error and to often exhibit a low correlation with ing to the training samples), the loo regression error, the mean test-set errors [35]."
6,"with regard to the rademacher complexity, absolute error (mae), and the root-mean-square error (rmse) it is worth noting that the related bound holds for a kernel- on the test set were computed as functions of c and Îµ, with based functional approximator with no bias term [30], whereas c âˆˆ [10âˆ’3 , 106 ] and Îµ âˆˆ [10âˆ’4 , 10âˆ’2 ] (the kernel parameter Ïƒ the svm estimator in (1) includes the bias term bâˆ— ."
6,"hence, was set to a constant value, i.e., 0.25, so that the plots could be the application of this error bound in the present case is not drawn; see fig."
6,"1). formally rigorous, which may explain the lack of correlation in the analyzed ranges of c and Îµ, the span bound, the loo with the test-set errors."
6,"from this perspective, possible gen- error, and the test mae and rmse have similar valleylike nearly eralizations of the rademacher complexity bound to kernel- Îµ-insensitive shapes, with small and large values of c causing based expansions with bias terms may be proven and tested as larger function values."
6,"this is an expected behavior, according well, even though this further development would be outside to the meaning of the parameter c in svm training (see the scope of this paper."
6,section ii-a).
6,"however, mae, rmse, and the loo error have it is also worth noting that, even if the span bound and test slightly wider valley floors than the span bound; this suggests mae and rmse minima are not achieved by the same parameter that the span bound may tend to overestimate regression errors configuration, the values of mae and rmse obtained by the for large values of c."
6,"in particular, the span bound is a very parameter configuration yielding the smallest span bound differ tight upper bound on the loo error in the valley floor area (on from the minima mae and rmse by just 0.08 k and 0.13 k, average, the span bound is just 0.8% higher than the loo error respectively."
6,"the similar behaviors of these three functions in this area), while it is a coarser bound for large values of c. of (c, Îµ) are also confirmed by the fact that the correlation although not shown here for brevity, the behaviors of mae coefficients between the span bound and mae and between the and rmse on the training set are very similar to those of their span bound and rmse are 96.3% and 96.9%, respectively."
6,"this test counterparts, except for slightly better overall values (as is pivotal, as it confirms that, by minimizing the span bound, expected). the resulting parameter configuration may also lead to good on the contrary, both the radius-margin and rademacher regression performance on unknown samples."
6,"similar results complexity bounds exhibited a strictly monotonic behavior with (not shown for brevity) were obtained for the behaviors of the no local/global minima, which makes them unfit to guide the considered functionals as functions of (c, Ïƒ) and (Îµ, Ïƒ) and parameter optimization process, at least on the considered data with the other two data sets as well."
6,authorized licensed use limited to: univ of calif santa barbara.
6,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
6,restrictions apply.
7,moser and serpico: parameter optimization for regression for land and sst estimation 915 c.
7,"experiment ii: temperature estimation table i experiment ii, data set â€œlst-avhrr-mesonetâ€: mae, rmse, the proposed psb method was initialized with c 0 = 1, Îµ0 = and m ean e rror on the t est s et for the svm f unctional approximators obtained by the psb and grid-search 0.01, and Ïƒ 0 = 0.5, and applied to each of the three considered parameter optimization methods (cv, hold-out), data sets."
7,"four and five iterations were sufficient for psb to correlation coefficient Ï between the true and estimated converge in the cases of â€œsstâ€ and of the two lst data sets, temperatures of the test samples, slope and intercept of the l inear r egression of the e stimated t emperatures w ith respectively."
7,"the results were compared with the ones obtained respect to the true ones, computation times for the training by two grid-search approaches."
7,"in the first approach, a hold- phases, and training and test-sample sizes."
7,"the related out strategy was used, i.e., for each node in the grid, an svm parameter values are also reported was trained on the training set, and then, the parameter vector yielding the smallest mae on the test set was searched for in the grid."
7,this represents an â€œideal caseâ€ in which the true in situ temperatures are assumed to be known also on the test samples; this is not a realistic parameter optimization strategy but is included here as a benchmark experiment.
7,"the second grid ap- proach searched for the parameter vector yielding the smallest cv mae, computed, as usual, on the training samples; this is a feasible and popular parameter optimization technique."
7,"a three- fold cv, with a random subdivision of the training set into three disjoint almost-equal-sized subsets, was used."
7,"in both cases, the considered set of values were c âˆˆ {10âˆ’3 , 10âˆ’2 , . . . , 104 }, Îµ âˆˆ {10âˆ’4 , 10âˆ’3 , . . . , 10âˆ’1 }, and Ïƒ âˆˆ {0.01, 0.02, . . . , 1}."
7,"table ii experiment ii, data set â€œlst-msg-arsiaâ€: mae, rmse, and mean the test-set accuracies obtained by using svms with the error on the test set for the svm functional approximators parameter configurations computed by psb and by the two obtained by the psb and grid-search parameter optimization grid searches are presented in tables iâ€“iii."
7,"all considered methods (cv, hold-out), correlation coefficient Ï between the true and estimated temperatures of the test samples, slope parameter optimization techniques allowed accurate temper- and i ntercept of the l inear r egression of the e stimated ature estimates to be generated with mae 1â€“1.5 k and temperatures with respect to the true ones, computation rmse 1.3â€“2 k in the lst case and mae 0.5 k and times for the training phases, and training and test-sample sizes."
7,the related parameter values are also reported rmse 0.7 k in the sst case.
7,the correlation coefficient Ï between the true and estimated temperatures on the test samples was very high for the â€œsstâ€ (Ï 99%) and â€œlst-avhrr- mesonetâ€ (Ï > 97%) data sets and quite high for â€œlst-msg- arsiaâ€ (Ï 86%â€“88%).
7,this is consistent with the fact that the estimated temperatures exhibited smaller mean errors with respect to the true ones in the cases of â€œlst-avhrr-mesonetâ€ (mean error below 0.1 k) and â€œsstâ€ (mean error below 0.2 k) than in the case of â€œlst-msg-arsiaâ€ (mean error around 0.7 k).
7,"similarly, the intercepts of the linear regression of the estimated temperatures with respect to the true ones were larger with â€œlst-msg-arsiaâ€ than with â€œlst-avhrr-mesonetâ€ and â€œsst.â€"
7,this is interpreted as a consequence of the lower correlation of the satellite infrared observations with the in situ even smaller differences can be noted between the regression measurements for â€œlst-msg-arsia.â€
7,"for instance, the cor- errors of psb and of the cv grid search: slightly smaller values relation coefficients between the in situ temperatures and the of mae and rmse were obtained by cv, when applied to â€œsstâ€ brightness temperature channels were 95% Ã· 96% for both and â€œlst-avhrr-mesonet,â€ and by psb, when applied to â€œsstâ€ and â€œlst-avhrr-mesonetâ€ and just 76% for â€œlst- â€œlst-msg-arsia.â€"
7,the fact that quite different parameter msg-arsia.â€ vectors computed by psb and by the grid searches resulted the parameter vectors identified by psb were quite different in very similar regression performances can be explained by from the grid-search ones.
7,"however, very similar performances the valleylike behaviors of the span-bound, mae, and rmse were exhibited by the three approaches, with slightly smaller functionals described in section iii-b. regression errors on the hold-out grid search."
7,"this is an ex- on the other hand, dramatic differences can be noticed pected result as this approach also exploits the true in situ between the computation times of psb and of the grid-search temperatures of the test samples."
7,"however, the differences for lst estimation (all times in tables iâ€“iii refer to the same between the values of mae for psb and for the hold-out hardware configuration, i.e., a 3.4-ghz cpu with 1-gb ram). grid search were just 0.07 k for â€œlst-avhrr-mesonetâ€ and the grid search, when applied to the two lst data sets in â€œsstâ€ and 0.11 k for â€œlst-msg-arsia,â€ and the differences both the cv and hold-out versions, required some hours to between the corresponding rmse values were 0.07 k for â€œlst- identify optimal parameter vectors and to train the related svm msg-arsiaâ€ and â€œsstâ€ and 0.12 k for â€œlst-msg-arsia.â€ approximators due to the need to repeat the qp solution process authorized licensed use limited to: univ of calif santa barbara."
7,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
7,restrictions apply.
8,"916 ieee transactions on geoscience and remote sensing, vol."
8,"47, no."
8,"3, march 2009 table iii borders between sea and land or near cloud-covered areas due experiment ii, data set â€œsstâ€: mae, rmse, and mean error on the t est s et for the svm f unctional a pproximators o btained to the effect of mixed pixels."
8,"by the psb and g rid -s earch p arameter o ptimization m ethods (cv, hold-out), correlation coefficient Ï between the true and e stimated t emperatures of the t est s amples , s lope and d."
8,"experiment iii: sensitivity to initialization intercept of the linear regression of the estimated temperatures with respect to the true ones, computation psb is iterative and is initialized with a predefined param- times for the training phases, and training and test-sample sizes."
8,the related parameter values are also reported eter vector.
8,a further experiment was performed to assess the sensitivity of the method to this initialization.
8,"the initial parameter values were varied in the ranges c 0 âˆˆ [0.1; 10], Îµ0 âˆˆ [0.001; 0.1], Ïƒ 0 âˆˆ [0.1; 1], and a grid of 250 points was defined according to these ranges."
8,"for each of the three data sets, psb was initialized to each node in the grid and was run until convergence."
8,"the mae and rmse values, computed on the test sets and averaged over the 250 runs, are shown in table iv, together with the related standard deviations."
8,"when varying the initial parameter values in the aforemen- tioned ranges, psb converged, as expected, to different local minima of the span bound."
8,"however, a remarkable stability of the resulting test-set errors was noted."
8,"for all three data sets, the standard deviations of mae and rmse were much smaller than the corresponding average values, which, in particular, were at each node in the grid."
8,"the difference in computation times very close to the values reported in tables iâ€“iii for the specific is less significant in the case of â€œsstâ€ because the number of case c 0 = 1, Îµ0 = 0.01, and Ïƒ 0 = 0.5."
8,"this is consistent with available training samples is smaller for this data set than for the the behaviors of the span bound and of the test-set errors two lst data sets, and the time required by each qp numerical discussed in section iii-a, which presented large valleylike solution is correspondingly much shorter [16]."
8,"as expected, the shapes including many local minima corresponding to different 3-fold cv turned out to be the most time-consuming technique, parameter configurations and to almost equivalent regression as it performed three qp solutions for each node in the grid, performances. even though on smaller training sets as compared with the hold- fig. 3 shows the histograms of the computation times taken out case."
8,"on the other hand, in order to complete the parameter by psb (applied to the three data sets) in the 250 runs."
8,"the optimization and training processes, psb required about just average times were 29 min 55 s, 1 min 17 s, and 3 min 38 s 47 s, 2 min, and 36 min for â€œlst-msg-arsia,â€ â€œsst,â€ and in the cases of â€œlst-avhrr-mesonet,â€ â€œlst-msg-arsia,â€ â€œlst-avhrr-mesonet,â€ respectively."
8,"this is explained by the and â€œsst,â€ respectively."
8,such times were shorter than the fact that grid searches perform a complete exploration of the corresponding ones required by cv or hold-out grid searches parameter space (up to the adopted search ranges and quan- (see tables iâ€“iii).
8,"however, the choice of the initial parameter tization steps), whereas psb performs a sequence of moves vector affected the time required by psb to converge to a local (in the parameter space), which approaches a locally optimum minimum for each run."
8,when considering the two lst data solution.
8,"from this viewpoint, psb is a suboptimal approach, sets, the computation times of all psb runs were (much) shorter even though it still identifies parameter configurations affected than those of the grid searches."
8,"on the other hand, in the case of by regression errors very close to the ones incurred by grid â€œsst,â€ psb took a longer time than cv in 57 out of 250 runs. searches."
8,"in fact, thanks to the small training-sample size of this data set, fig. 2(b) and (c) shows the maps of lst estimates obtained cv required a short time."
8,"such results further confirm that psb, by applying the svms trained on the â€œlst-msg-arsiaâ€ as compared with grid searches, yields a relevant reduction training set (with the parameter vectors computed by psb and in the computational burden when many training samples are by the hold-out grid search, respectively) to an msg image available, whereas this advantage may not be significant in acquired over italy on september 15, 1999, at 7:00 a ."
8,"m . local small-sample-size cases, in which the execution time of grid time [fig. 2(a)]."
8,a visual comparison between such maps searches is already noncritical. further confirms the close similarity between the psb and grid- search results.
8,similar remarks hold for the â€œlst-avhrr- e.
8,experiment iv: bias-variance analysis mesonetâ€ data set as well.
8,"the same visual conclusions can be drawn from fig. 2(e) and (f), which shows the maps of sst a specific experiment was carried out in order to investigate estimates obtained by applying the svms trained on the â€œsstâ€ possible overfitting issues related to psb."
8,"we recall that, given training set (with the parameter vectors computed by psb and the regression problem consisting in the estimation of a random by the hold-out grid search) to an avhrr image acquired over variable y as a function of an n-dimensional feature vector x, porto alegre (brazil) on january 15, 1999, at 3:42 p."
8,"m . local assuming a set d = {(x1 , y1 ), (x2 , y2 ), . . . , (xn , yn )} of i.i.d. solar time [fig. 2(d)]."
8,"we note that, in these maps, very low training samples to be available, and denoting fË†d (Â·) as the func- sst estimates were erroneously obtained in some pixels at the tional approximator obtained by training with d a supervised authorized licensed use limited to: univ of calif santa barbara."
8,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
8,restrictions apply.
9,moser and serpico: parameter optimization for regression for land and sst estimation 917 fig.
9,"experiment ii: (a) msg image acquired over italy on september 15, 1999, at 7:00 a ."
9,"m . local time (the 10.8-Î¼m brightness temperature channel is shown). (b) map of lst estimates generated by svm regression with parameters optimized by psb. (c) map of lst estimates generated by svm regression with parameters optimized by the hold-out grid search. (d) avhrr image acquired over porto alegre (brazil) on january 15, 1999, at 3:42 p."
9,m . local solar time (avhrr channel 4 is shown). (e) map of lst estimates generated by svm regression with parameters optimized by psb. (f) map of lst estimates generated by svm regression with parameters optimized by the hold-out grid search. (g) color legend for the temperature maps.
9,"cloud-covered areas are masked in white in all the images, together with sea areas in (a)â€“(c) and with land areas in (d)â€“(f)."
9,"table iv experiment iii: means and standard deviations (stdev) of the mae and rmse values obtained by psb on the test sets of the three considered data sets, when varying the initial parameter vector in a predefined grid of 250 points fig."
9,"experiment iii: histograms of the computation times required by psb to reach convergence, when varying the initial parameter vector in a predefined grid of 250 points. (a) â€œlst-avhrr-mesonet.â€ (b) â€œlst-msg-arsia.â€ (c) â€œsst.â€ regression technique (e.g., an svm or a neural network), the of the target variable y."
9,"the second contribution represents a mse on an unknown test sample x can be decomposed as the measure of the average bias of the adopted estimator fË†d (x) sum of three contributions [51] with respect to the conditional mean e{y|x}, which is known  2  to be the optimal estimator in the mse sense [52] (and which mse(x) = e y âˆ’ fË†d (x) |x is usually unknown)."
9,the third contribution is a measure of the variance of the estimator fË†d (x) as a function of the (random)    2 training samples in d.
9,"a tradeoff (namely, the so-called â€œbias- = var{y|x} + e fË†d (x)|x âˆ’ e{y|x} variance dilemmaâ€) often holds between the bias and variance   terms [51]."
9,"for instance, sharply reducing the bias may cause + var fË†d (x)|x . (6) overfitting phenomenon, which is likely to yield an increase in the variance."
9,"the first term does not depend on the adopted estimator and for each of the three considered data sets, in order to perform is related to the intrinsic data variability (e.g., due to noise) a â€œbias-varianceâ€ analysis of psb, 100 subsets were randomly authorized licensed use limited to: univ of calif santa barbara."
9,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
9,restrictions apply.
10,"918 ieee transactions on geoscience and remote sensing, vol."
10,"47, no."
10,"3, march 2009 table v experiment iv: square roots of the integrated bias, variance, and mse computed on the test set of each of the considered data sets, according to the lst/sst estimators obtained by running psb over 100 randomly selected training subsets sampled from the available training set."
10,"according to the experimental results on both sst and lst data sets gener- available training-sample sizes (tables iâ€“iii), each subset was ated by the proposed psb method turned out to be very similar made of about 100 samples for â€œlst-avhrr-mesonetâ€ and to those obtained by a classical grid-search approach based on of about 50 samples for â€œlst-msg-arsiaâ€ and â€œsst.â€"
10,psb cv on the sets of available training samples.
10,"slightly worse was initialized with c 0 = 1, Îµ0 = 0.01, and Ïƒ 0 = 0.5 and was results were obtained as compared with the ones provided by run until convergence over each training subset, thus yielding a further grid search for the parameter configuration yielding a distinct trained svm estimator."
10,"then, the â€œintegrated bias,â€ the smallest mae on the test set, assuming the true in situ â€œintegrated variance,â€ and â€œintegrated mseâ€ were computed on temperature values to be known also on test samples."
10,"however, the test set (see table v), which represent estimates of the the differences between the maes and rmses of this â€œidealâ€ average bias, variance, and mse values."
10,details about such benchmark case and the ones of the proposed technique were estimates can be found in [51].
10,"here, we only remark that they very small for all the considered data sets. rely on the assumption that the mse contribution related to on the other hand, the computation time of psb, when intrinsic data variability in (6) is negligible when compared applied to the two lst data sets, turned out to be much shorter to the other two terms."
10,the resulting â€œintegrated mseâ€ is equal than the execution times of grid searches.
10,"in the case of sst, to the average of the 100 mse values obtained on the test set by the difference between the times taken by the two approaches the functional approximators trained on the 100 subsets. was lower due to the smaller number of training samples."
10,we first note that the root integrated mse values in table v this demonstrates the capabilities of psb to jointly exhibit were slightly higher than the rmse values in tables iâ€“iii.
10,this accuracies very close to those achieved by grid searches and is probably because of the much smaller size of the training to require a much lower computational burden.
10,note that the subsets involved in this experiment as compared to the original training sets employed here for experiments were made of a few training-sample sizes.
10,"for all three data sets and, in particular, hundred samples."
10,"even in such cases, the grid searches required for the two lst ones, the resulting integrated biases were several hours to complete the training process, which makes significantly larger than the corresponding integrated variances. them critical from a computational viewpoint, when applied the integrated bias was equal to 85%, 86%, and 63% of the with much larger training sets (the training time of an svm corresponding integrated mses for â€œlst-avhrr-mesonet,â€ is known to increase at least quadratically with the training- â€œlst-msg-arsia,â€ and â€œsst,â€ respectively."
10,this suggests sample size [16]).
10,"in addition, a grid search for the lowest that the test-set errors can be mainly ascribed to the over- cv or hold-out error preliminarily requires the user/operator all difference between the functional approximator generated to manually predefine a search range and a quantization step on by psb and the (unknown) conditional mean of the target each parameter."
10,"on the other hand, the proposed method can be lst/sst given the feature values, and it is not because of suggested as a feasible tool for fully automatic and much faster large fluctuations in the approximator as the training samples training with essentially equivalent accuracies and without the are varied."
10,this suggests a rather small sensitivity of psb to need for user interaction.
10,"this is important for an operational the choice of specific sets of training samples, thus limiting the use of the svm-based approach to lst/sst estimation in related risks of overfitting. order to speed up the update of the functional approximator which is regularly used to generate maps of surface temperature iv."
10,c onclusion estimates.
10,"from this perspective, the integration of the proposed approach with incremental learning procedures (e.g., [53]) is a in this paper, a novel automatic parameter optimization future extension worth investigating. method has been proposed for svm regression and validated the proposed method is iterative and is initialized with a in the context of lst and sst estimation from satellite in- starting parameter configuration."
10,"however, the choice of this frared data."
10,"the method integrates the span-bound functional, initial configuration turns out not to be critical."
10,"it influences the developed in [35] as an upper bound on the loo regres- specific local minimum to which powellâ€™s algorithm converges, sion error, with powellâ€™s numerical minimization algorithm in but without significantly affecting the test-set regression errors. order to identify a quasi-optimal parameter configuration as the initial parameter vector has a stronger impact on the time compared with the criterion of the minimum estimation error. taken by powellâ€™s procedure to reach convergence."
10,"regardless, experiments on three data sets, consisting of avhrr and in the cases of both lst data sets, this time was always msg satellite images with synchronous in situ measurements significantly shorter than the one required by grid searches."
10,"in of lst and sst, pointed out strongly correlated behaviors of the sst experiments, the time of cv and the average time of the aforesaid functional and of the mae and rmse regression psb were comparable because of the aforementioned smaller errors on test sets, thus confirming the appropriateness of the number of training samples in this data set."
10,an interesting choice of this theoretical upper bound. possible extension of the proposed technique might lie in the authorized licensed use limited to: univ of calif santa barbara.
10,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
10,restrictions apply.
11,"moser and serpico: parameter optimization for regression for land and sst estimation 919 application of global minimization methods (e.g., genetic or perature measurements in oklahoma (usa) and to avhrr evolutionary algorithms [54]) to the span-bound functional. data, respectively; arsia for acquiring temperature measure- this may prevent convergence to local minima, even though ments in tuscany (italy), prof."
11,castelli from the univer- possibly increasing the computation time and requiring further sity of florence (italy) for providing such measurements; the parameters of the minimization procedure to be tuned.
11,"it might avhrr pathfinder oceans group of the university of miami also be worth integrating the proposed lst estimation method (usa) for allowing free web access to the avhrr pathfinder with soil/atmosphere interface energy flux models (e.g., for matchup database of sst measurements; dr."
11,"chang and flood prevention and monitoring) [55], [56]."
11,lin from the university of taipei (taiwan) for free- a further analysis of the behavior of psb from the viewpoint ware providing the libsvm software package; dr.
11,zortea of the â€œbias-variance dilemmaâ€ was also performed by itera- for his assistance in data preparation and preprocessing; and tively running psb on randomly selected training subsets and a.
11,agneessens for his help with the experiments. then by estimating the integrated biases and variances of the resulting estimators.
11,the experimental results suggested that r eferences the integrated bias contributions were dominant with respect to [1] p.
11,"dash, f.-m."
11,"gottsche, f.-s."
11,"olesen, and h."
11,"fischer, â€œland surface tem- the integrated variances for the three data sets, which suggests perature and emissivity estimation from passive sensor data: theory and that psb has a limited sensitivity to the specific choice of the practiceâ€”current trends,â€ int."
11,"remote sens., vol. 23, no. 13, pp. 2563â€“ training samples (provided that they are drawn from the same 2594, jul."
11,[2] s.
11,"haines, g."
11,"jedlovec, and s."
11,"lazarus, â€œa modis sea surface probability distribution). temperature composite for regional applications,â€ ieee trans."
11,geosci.
11,"we note that the presented lst experiments referred remote sens., vol. 45, no. 9, pp."
11,"2919â€“2927, sep."
11,[3] k.
11,"mao, j."
11,"shi, h."
11,"tang, z.-l."
11,"li, x."
11,"wang, and k.-s."
11,"chen, â€œa neural to avhrr and msg images acquired between 7:00 and network technique for separating land surface emissivity and temperature 9:00 a ."
11,m . (local times).
11,"further experiments (not presented from aster imagery,â€ ieee trans."
11,geosci.
11,"remote sens., vol. 46, no. 1, here for the sake of brevity) on msg images acquired be- pp."
11,"200â€“208, jan."
11,[4] l.
11,peres and c.
11,"dacamara, â€œimproving two-temperature method tween 9:00 a ."
11,m . and 6:00 p.
11,"m . (local times) further confirm retrievals based on a nonlinear optimization approach,â€ ieee geosci. the similarity of the regression accuracies of the proposed remote sens."
11,"lett., vol. 3, no. 2, pp."
11,"232â€“236, apr."
11,2006. technique to those of grid searches and the large differences [5] j.
11,jimenez-munoz and j.
11,"sobrino, â€œfeasibility of retrieving land- surface temperature from aster tir bands using two-channel algo- in the related computation times."
11,"furthermore, the choices of rithms: a case study of agricultural areas,â€ ieee geosci."
11,"remote sens. the features used in the regression experiments were suggested lett., vol. 4, no. 1, pp."
11,"60â€“64, jan."
11,"2007. by traditional physically based split-window approaches [47], [6] i."
11,"barton, â€œsatellite-derived sea surface temperaturesâ€”a comparison between operational, theoretical, and experimental algorithms,â€ j."
11,"[48], [50]."
11,"as further developments of this paper, it would be meteorol., vol. 31, no. 5, pp."
11,"432â€“442, may 1992. interesting to validate the proposed method by considering, also [7] p.-k."
11,chan and b.-c.
11,"gao, â€œa comparison of modis, ncep, and tmi sea in the lst case, the satellite zenith angle among the input surface temperature datasets,â€ ieee geosci."
11,remote sens.
11,"lett., vol. 2, no. 3, pp."
11,"270â€“274, jul."
11,2005. features (thanks to its relationship with atmospheric absorption [8] l.
11,peres and c.
11,"dacamara, â€œinverse problems theory and applica- [13]) and, more generally, by automating the feature-extraction tion: analysis of the two-temperature method for land-surface tempera- stage through the use of supervised (e.g., kernel-based [57]) ture and emissivity estimation,â€ ieee geosci."
11,remote sens.
11,"lett., vol. 1, no. 3, pp."
11,"206â€“210, jul."
11,2004. algorithms to compute sets of features that optimize regression [9] l.
11,peres and c.
11,"dacamara, â€œemissivity maps to retrieve land-surface accuracy. temperature from msg/seviri,â€ ieee trans."
11,geosci.
11,"remote sens., it is worth noting that, even though the proposed technique vol. 43, no. 8, pp."
11,"1834â€“1844, aug."
11,[10] c.
11,"pinheiro, j."
11,"privette, r."
11,"mahoney, and c."
11,"tucker, â€œdirec- has been experimentally tested in the context of surface tem- tional effects in a daily avhrr land surface temperature dataset over perature estimation, it is not application specific."
11,"the span africa,â€ ieee trans."
11,geosci.
11,"remote sens., vol. 42, no. 9, pp. 1941â€“1954, bound is a general bound on the loo error of support vector sep."
11,[11] a.
11,"rodger, l."
11,"balick, and w."
11,"clodius, â€œthe performance of the regression."
11,"from a methodological viewpoint, this suggests multispectral thermal imager (mti) surface temperature retrieval algo- that psb is a general locally optimum parameter optimization rithm at three sites,â€ ieee trans."
11,geosci.
11,"remote sens., vol. 43, no. 3, algorithm for this family of regression techniques."
11,on the other pp.
11,"658â€“665, mar."
11,[12] d.
11,sun and r.
11,"pinker, â€œcase study of soil moisture effect on land hand, a further validation on different regression problems (e.g., surface temperature retrieval,â€ ieee geosci."
11,remote sens.
11,"lett., vol. 1, estimation of other bio-/geophysical parameters of the earthâ€™s no. 2, pp."
11,"127â€“130, apr."
11,2004. surface) would be required to appreciate the effectiveness of [13] y.
11,"yu, j."
11,"privette, and a."
11,"pinheiro, â€œevaluation of split-window land surface temperature algorithms for generating climate data records,â€ the method, particularly compared to grid searches, in other ieee trans."
11,geosci.
11,"remote sens., vol. 46, no. 1, pp. 179â€“192, applicative contexts as well."
11,this would be an important de- jan.
11,[14] c.
11,merchant and p.
11,"borgne, â€œretrieval of sea surface temperature velopment of this paper."
11,"it would also be interesting to extend from space, based on modeling of infrared radiative transfer: capabilities the method to svm-based regression with quadratic penalty and limitations,â€ j."
11,atmos.
11,ocean.
11,"technol., vol. 21, no. 11, pp. 1734â€“ on the slack variables by combining the related span-bound 1746, nov."
11,[15] m.
11,"zortea, m."
11,"de martino, g."
11,"moser, and s."
11,"serpico, â€œland formulation [35] with powellâ€™s algorithm. surface temperature estimation from infrared satellite data using sup- port vector machines,â€ in proc."
11,"igarss, denver, co, jul."
11,"31,â€“aug."
11,"4, acknowledgment 2006, pp."
11,2109â€“2112.
11,[16] v.
11,"vapnik, statistical learning theory."
11,"new york: wiley- the authors would like to thank cima for providing the interscience, 1998."
11,[17] y.
11,bazi and f.
11,"melgani, â€œsemisupervised pso-svm regression for msg images used for the experiments; oklahoma mesonet biophysical parameter estimation,â€ ieee trans."
11,geosci.
11,"remote sens., and noaa for allowing free web access to in situ tem- vol. 45, no. 6, pp."
11,"1887â€“1895, jun."
11,authorized licensed use limited to: univ of calif santa barbara.
11,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
11,restrictions apply.
12,"920 ieee transactions on geoscience and remote sensing, vol."
12,"47, no."
12,"3, march 2009 [18] l."
12,bruzzone and f.
12,"melgani, â€œrobust multiple estimator systems for the [42] m."
12,"powell, â€œan efficient method for finding the minimum of a analysis of biophysical parameters from remotely sensed data,â€ ieee function of several variables without calculating derivatives,â€ comput."
12,"j., trans."
12,geosci.
12,"remote sens., vol. 43, no. 1, pp."
12,"159â€“174, jan."
12,"2005. vol. 7, no. 2, pp."
12,"155â€“162, feb."
12,[19] g.
12,"camps-valls, l."
12,"bruzzone, j."
12,"rojo-alvarez, and f."
12,"melgani, â€œro- [43] r."
12,"brent, algorithms for minimization without derivatives."
12,"englewood bust support vector regression for biophysical variable estimation from cliffs, nj: prentice-hall, 1973. remotely sensed images,â€ ieee trans."
12,geosci.
12,"remote sens., vol."
12,"44, [44] d."
12,"pozo vazquez, f."
12,"reyes, and l."
12,"arboledas, â€œa comparative no. 3, pp."
12,"339â€“343, jul."
12,2006. study of algorithms for estimating land surface temperature from avhrr [20] g.
12,"camps-valls, l."
12,"gomez-chova, j."
12,"munoz-mari, j."
12,"vila-frances, data,â€ remote sens."
12,"environ., vol. 62, no. 3, pp."
12,"215â€“222, dec."
12,"amoros-lopez, and j."
12,"calpe-maravilla, â€œretrieval of oceanic chloro- [45] j."
12,"sobrino, j."
12,"jimenez-munoz, m."
12,"el-kharraz-gomez, phyll concentration with relevance vector machines,â€ remote sens."
12,envi- m.
12,"romaguera, and g."
12,"soria, â€œsingle-channel and two-channel methods ron., vol. 105, no. 1, pp."
12,"23â€“33, nov."
12,2006. for land surface temperature retrieval from dais data and its application [21] f.
12,"yang, m."
12,"white, a."
12,"michaelis, k."
12,"ichii, h."
12,"hashimoto, p."
12,"votava, to the barrax site,â€ int."
12,"remote sens., vol. 25, no. 1, pp."
12,"215â€“230, a.-x."
12,"zhu, and r."
12,"nemani, â€œprediction of continental-scale evapo- jan."
12,2004. transpiration by combining modis and ameriflux data through support [46] h.
12,"ouaidrari, s.n."
12,"goward, k.p."
12,"czajkowski, j.a."
12,"sobrino, and vector machine,â€ ieee trans."
12,geosci.
12,"remote sens., vol. 44, no."
12,"11, e."
12,"vermote, â€œland surface temperature estimation from avhrr thermal pp."
12,"3452â€“3461, nov."
12,2006. infrared measurements: an assessment for the avhrr land pathfinder ii [22] s.
12,"durbha, r."
12,"king, and n."
12,"younan, â€œsupport vector machines data set,â€ remote sens."
12,"environ., vol. 81, no. 1, pp."
12,"114â€“128, 2002. regression for retrieval of leaf area index from multiangle imaging spec- [47] j."
12,sobrino and n.
12,"raissouni, â€œtoward remote sensing methods for land troradiometer,â€ remote sens."
12,"environ., vol. 107, no. 1/2, pp. 348â€“361, cover dynamic monitoring: application to morocco,â€ int."
12,"remote sens., mar."
12,"2007. vol. 21, no. 2, pp."
12,"353â€“366, 2000."
12,[23] o.
12,"chapelle, v."
12,"vapnik, o."
12,"bousquet, and s."
12,"mukherjee, â€œchoosing mul- [48] c."
12,"ulivieri, m."
12,"castronuovo, r."
12,"francioni, and a."
12,"cardillo, â€œa split tiple parameters for support vector machines,â€ mach."
12,"learn., vol. 46, window algorithm for estimating land surface temperature from satel- no. 1â€“3, pp."
12,"131â€“159, jan."
12,"2002. lites,â€ adv."
12,"space res., vol. 14, no. 3, pp."
12,"59â€“65, mar."
12,[24] k.-m.
12,"chung, w.-c."
12,"kao, t."
12,"sun, l.-l."
12,"wang, and c.-j."
12,"lin, â€œradius [49] r."
12,evans and g.
12,"podestÃ¡, â€œnoaa/nasa avhrr oceans pathfinder sea margin bounds for support vector machines with the rbf kernel,â€ neural surface temperature data set userâ€™s reference manual,â€ noaa/nasa, comput., vol. 15, no. 11, pp."
12,"2643â€“2681, nov."
12,"washington, dc, 1998."
12,[online].
12,available: http://www.
12,[25] k.
12,"duan, s."
12,"keerthi, and a."
12,"poo, â€œevaluation of simple performance rsmas.miami.edu/groups/ rrsl/pathfinder/ measures for tuning svm hyperparameters,â€ neurocomputing, vol."
12,"51, [50] x."
12,"li, w."
12,"pichel, e."
12,"maturi, p."
12,"clemente-colon, and j."
12,"sapper, â€œderiving pp."
12,"41â€“59, apr."
12,2003. the operational nonlinear multichannel sea surface temperature algorithm [26] t.
12,"joachims, â€œestimating the generalization performance of an svm effi- coefficients for noaa-15 avhrr/3,â€ int."
12,"remote sens., vol. 22, no. 4, ciently,â€ in proc."
12,"learn., 2000, pp."
12,431â€“438. pp.
12,"699â€“704, 2001."
12,[27] g.
12,"wahba, y."
12,"lin, and h."
12,"zhang, â€œgacv for support vector machines,â€ [51] s."
12,"geman, e."
12,"bienenstock, and r."
12,"doursat, â€œneural networks and in advances in large margin classifiers, a."
12,"smola, p."
12,"bartlett, the bias/variance dilemma,â€ neural comput., vol. 4, no. 1, pp."
12,"1â€“58, b."
12,"scholkopf, and d."
12,"schuurmans, eds."
12,"cambridge, ma: mit press, jan."
12,[52] a.
12,papoulis and s.
12,"pillai, probability, random variables, and stochas- [28] v."
12,vapnik and o.
12,"chapelle, â€œbounds on error expectation for support tic processes."
12,"new york: mcgraw-hill, 2002. vector machine,â€ in advances in large margin classifiers, a."
12,"smola, [53] w."
12,"wang, â€œan incremental learning strategy for support vector regres- p."
12,"bartlett, b."
12,"scholkopf, and d."
12,"schuurmans, eds."
12,"cambridge, ma: sion,â€ neural process."
12,"lett., vol. 21, pp."
12,"175â€“188, 2005."
12,"mit press, 1999."
12,[54] z.
12,"michalewicz, genetic algorithms + data structures = evolution [29] c."
12,"burges, a tutorial on support vector machines for pattern recogni- programs."
12,"new york: springer-verlag, 1996. tion."
12,"boston, ma: kluwer, 1998."
12,[55] g.
12,"boni, f."
12,"castelli, and d."
12,"entekhabi, â€œsampling strategies and assimi- [30] p."
12,bartlett and s.
12,"mendelson, â€œrademacher and gaussian complexities: lation of ground temperature for the estimation of surface energy balance risk bounds and structural results,â€ j."
12,learn.
12,"res., vol. 3, pp. 463â€“ components,â€ ieee trans."
12,geosci.
12,"remote sens., vol. 39, no. 1, pp."
12,"165â€“ 484, mar."
12,"172, jan."
12,[31] v.
12,cherkassky and y.
12,"ma, â€œpractical selection of svm parameters and [56] f."
12,caparrini and f.
12,"castelli, â€œmapping of landâ€“atmosphere heat fluxes and noise estimation for svm regression,â€ neural netw., vol. 17, no. 1, surface parameters with remote sensing data,â€ boundary-layer meteorol., pp."
12,"113â€“126, jan."
12,"2003. vol. 107, no. 3, pp."
12,"605â€“633, jun."
12,[32] j.
12,kwok and i.
12,"tsang, â€œlinear dependency between  and the input [57] j."
12,shawe-taylor and n.
12,"cristianini, kernel methods for pattern analysis. noise in -support vector regression,â€ ieee trans."
12,"neural netw., vol."
12,"14, cambridge, u.k.: cambridge univ."
12,"press, 2004. no. 3, pp."
12,"544â€“553, may 2003."
12,[33] w.
12,"chu, s."
12,"keerthi, and c."
12,"ong, â€œbayesian support vector regression using a unified loss function,â€ ieee trans."
12,"neural netw., vol. 15, no. 1, pp."
12,"29â€“44, jan."
12,[34] j.
12,"gao, s."
12,"gunn, and c."
12,"harris, â€œa probabilistic framework for svm regression and error bar estimation,â€ mach."
12,"learn., vol. 46, no."
12,"1â€“3, gabriele moser (sâ€™03â€“mâ€™05) received the laurea pp."
12,"71â€“89, jan."
12,(m.s.) degree in telecommunications engineering [35] m.-w.
12,chang and c.-j.
12,"lin, â€œleave-one-out bounds for support vector (summa cum laude) and the ph.d. degree in space regression model selection,â€ neural comput., vol. 17, no. 5, pp. 1188â€“ sciences and engineering from the university of 1222, may 2005."
12,"genoa, genoa, italy, in 2001 and 2005, respectively."
12,[36] j.
12,"shawe-taylor, c."
12,"williams, n."
12,"cristianini, and j."
12,"kandola, â€œon the since 2001, he has been cooperating with the sig- eigenspectrum of the gram matrix and the generalization error of kernel- nal processing and telecommunications research pca,â€ ieee trans."
12,"theory, vol. 51, no. 7, pp."
12,"2510â€“2522, jul."
12,"group (sp&t), department of biophysical and elec- [37] w."
12,"press, s."
12,"teukolsky, w."
12,"wetterling, and b."
12,"flannery, nu- tronic engineering (dibe), university of genoa, in merical recipes in c."
12,"cambridge, u.k.: cambridge univ."
12,"press, 2002. the field of remote sensing image analysis."
12,from [38] m.
12,"zortea, â€œadvanced pattern recognition techniques for environmental january to march 2004, he was a visiting student information extraction from remotely sensed data,â€ ph.d. dissertation, with the institut national de recherche en informatique et en automatique, univ."
12,"genoa, genoa, italy, 2007."
12,"sophia antipolis, france, working with the â€œarianaâ€ research group on the [39] p."
12,"mantero, g."
12,"moser, and s."
12,"serpico, â€œpartially supervised classifi- problem of sar data modeling."
12,he is currently a research fellow at dibe.
12,"he cation of remote sensing images through svm-based probability density is also with the interuniversity research center in environmental monitoring estimation,â€ ieee trans."
12,geosci.
12,"remote sens., vol. 43, no. 3, pp."
12,"559â€“ (cima), savona, italy."
12,"his research activity is focused on image-processing 570, mar."
12,2005. and image-analysis methodologies for remote-sensing data interpretation.
12,in [40] r.-e.
12,"fan, p.-h."
12,"chen, and c.-j."
12,"lin, â€œworking set selection using second particular, his current research interests include sar data analysis, multitempo- order information for training support vector machines,â€ j."
12,"learn. ral image classification, hyperspectral image analysis, contextual classification, res., vol. 6, pp."
12,"1889â€“1918, dec."
12,2005. and geo-/biophysical parameter estimation.
12,[41] t.
12,"joachims, â€œmaking large-scale svm learning practical,â€ in advances in dr."
12,"moser has been an associate editor for the ieee geoscience and kernel methodsâ€”support vector learning, c."
12,burges and a.
12,"smola, eds."
12,remote sensing letters since 2008.
12,"he has been a reviewer for several cambridge, ma: mit press, 1999. international journals."
12,authorized licensed use limited to: univ of calif santa barbara.
12,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
12,restrictions apply.
13,moser and serpico: parameter optimization for regression for land and sst estimation 921 sebastiano b.
13,"serpico (mâ€™87â€“smâ€™00) received the laurea degree in electronic engineering and the ph.d. degree in telecommunications from the uni- versity of genoa, genoa, italy, in 1982 and 1989, respectively."
13,"since 1982, he has been cooperating with the de- partment of biophysical and electronic engineering (dibe), university of genoa, in the field of image processing and recognition."
13,"he was an assistant pro- fessor from 1990 to 1998 and an associate professor of telecommunications from 1998 to 2004 with the faculty of engineering, university of genoa, where he taught signal theory, pat- tern recognition, telecommunication systems, and electrical communications and is currently a full professor of telecommunications."
13,"from 1995 to 1998, he was the head of the signal processing and telecommunications research group (sp&t), dibe, and is currently the head of the sp&t laboratory."
13,he is the chairman of the institute of advanced studies in information and communication technologies.
13,"he is also with the interuniversity research center in environmental monitoring (cima), savona, italy."
13,"his current re- search interests include the application of pattern recognition (feature selection, classification, change detection, and data fusion) to remotely sensed images."
13,"he is the author or coauthor of more than 150 scientific publications, including journals and conference proceedings."
13,serpico was the recipient of the recognition of tgars best reviewers from the ieee geoscience and remote sensing society in 1998.
13,he coedited a special issue of the ieee transactions on geoscience and remote sensing on the subject of the analysis of hyperspectral image data (july 2001) and a special issue on advances in techniques for analysis of remotely sensed data (march 2005).
13,"since 2001, he has been an associate editor for the ieee transactions on geoscience and remote sensing."
13,he is a member of the international association for pattern recognition society.
13,authorized licensed use limited to: univ of calif santa barbara.
13,"downloaded on august 02,2024 at 22:20:25 utc from ieee xplore."
13,restrictions apply.
